"""
ğŸ“„ Document API Routes - Simplified
"""
import logging
import time
from typing import Dict, Any, Optional, List
from fastapi import APIRouter, UploadFile, File, HTTPException, Depends, Form, Query
from fastapi.responses import JSONResponse

from ..service.document_service import DocumentService
from ..service.vector_db_service import VectorDBService
from ..helper.pdf_loader_helper import PDFLoaderHelper

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/documents", tags=["documents"])

# ì„œë¹„ìŠ¤ ì˜ì¡´ì„± ì£¼ì…
async def get_document_service() -> DocumentService:
    """ë¬¸ì„œ ì„œë¹„ìŠ¤ ì˜ì¡´ì„± ì£¼ì…"""
    return DocumentService()

async def get_vector_service() -> VectorDBService:
    """ë²¡í„° DB ì„œë¹„ìŠ¤ ì˜ì¡´ì„± ì£¼ì… (ì „ì—­ ì„œë¹„ìŠ¤ ì‚¬ìš©)"""
    from ..main import global_vector_service
    if global_vector_service is None:
        raise HTTPException(status_code=500, detail="ì „ì—­ ë²¡í„° DB ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    return global_vector_service


# ğŸš€ 1. PDF ì—…ë¡œë“œ ë° ë²¡í„° ì €ì¥ (+ ë¬¸ì„œ ID ë°˜í™˜)
@router.post("/upload")
async def upload_pdf_to_vector_db(
    file: UploadFile = File(...),
    doc_service: DocumentService = Depends(get_document_service),
    vector_service: VectorDBService = Depends(get_vector_service)
) -> JSONResponse:
    """
    ğŸ“„ PDF íŒŒì¼ ì—…ë¡œë“œ ë° ë²¡í„° DB ì €ì¥ (ê°„ë‹¨ ë²„ì „)
    - íŒŒì¼ëª…ë§Œ ì…ë ¥, ë‚˜ë¨¸ì§€ëŠ” ìë™ ì²˜ë¦¬
    - ë²¡í„° DB: Milvus ìš°ì„  (ì „ì—­ ì„¤ì •)
    - ì²­í¬ í¬ê¸°: ìë™ ìµœì í™”
    """
    total_start_time = time.time()

    try:
        logger.info("=" * 50)
        logger.info("STEP1 PDF ì—…ë¡œë“œ ë° ë²¡í„° ì €ì¥ ì‹œì‘")

        # íŒŒì¼ ê²€ì¦
        if not file.filename or not file.filename.lower().endswith('.pdf'):
            raise HTTPException(status_code=400, detail="PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤")

        # PDF íŠ¹ì„± ë¶„ì„ ë° ìµœì  ë¡œë” ì„ íƒ
        analysis_start_time = time.time()
        logger.info("STEP2 PDF íŠ¹ì„± ë¶„ì„ ì‹œì‘")
        analysis_result = await PDFLoaderHelper.analyze_pdf_characteristics(file)
        analysis_time = time.time() - analysis_start_time
        logger.info(f"â±ï¸ PDF ë¶„ì„ ì™„ë£Œ: {analysis_time:.2f}ì´ˆ")

        # PDF ë‚´ìš© ì¶”ì¶œ
        extraction_start_time = time.time()
        logger.info("STEP3 PDF ë‚´ìš© ì¶”ì¶œ ì‹œì‘")
        extraction_result = await doc_service.process_pdf_with_dynamic_selection(
            file, analysis_result.recommended_loader
        )
        extraction_time = time.time() - extraction_start_time
        logger.info(f"â±ï¸ PDF ì¶”ì¶œ ì™„ë£Œ: {extraction_time:.2f}ì´ˆ")

        if not extraction_result["success"]:
            raise HTTPException(
                status_code=500,
                detail=f"PDF ì²˜ë¦¬ ì‹¤íŒ¨: {extraction_result.get('error', 'Unknown error')}"
            )

        # ğŸ”¥ ë²¡í„° DB ê°•ì œ Milvus ì´ˆê¸°í™” (ê¸°ì¡´ ì„œë¹„ìŠ¤ ë¬´ì‹œ)
        vector_init_start_time = time.time()
        logger.info("STEP4 Milvus ë²¡í„° DB ê°•ì œ ì´ˆê¸°í™”")
        await vector_service.force_switch_to_milvus()
        vector_init_time = time.time() - vector_init_start_time
        logger.info(f"â±ï¸ ë²¡í„° DB ì´ˆê¸°í™”: {vector_init_time:.2f}ì´ˆ")

        # ğŸ¯ ìë™ ì²­í¬ ì„¤ì • (í•œêµ­ì–´ ìµœì í™”)
        auto_chunk_size = 800  # í•œêµ­ì–´ì— ìµœì í™”ëœ í¬ê¸°
        auto_chunk_overlap = 100  # ì ë‹¹í•œ ì˜¤ë²„ë©

        # ë©”íƒ€ë°ì´í„° êµ¬ì„±
        metadata = {
            "filename": file.filename,
            "file_size": file.size,
            "pdf_loader": extraction_result["loader_used"],
            "language": analysis_result.language,
            "upload_timestamp": extraction_result["processing_time"],
            "source": "document_upload"
        }

        # ë²¡í„° DBì— ì €ì¥
        vector_store_start_time = time.time()
        logger.info("STEP5 Milvus ë²¡í„° DB ì €ì¥ ì‹œì‘")
        vector_result = await vector_service.store_pdf_content(
            pdf_content=extraction_result["content"],
            metadata=metadata,
            chunk_size=auto_chunk_size,
            chunk_overlap=auto_chunk_overlap
        )
        vector_store_time = time.time() - vector_store_start_time
        logger.info(f"â±ï¸ ë²¡í„° DB ì €ì¥ ì™„ë£Œ: {vector_store_time:.2f}ì´ˆ")

        # ğŸ”¥ íŒŒì¼ ID ê°€ì ¸ì˜¤ê¸° (íŒŒì¼ë³„ ë‹¨ì¼ ID)
        file_id = vector_result.get("file_id")

        # ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        total_time = time.time() - total_start_time

        # ê°„ë‹¨í•œ ì‘ë‹µ ë°˜í™˜
        response_data = {
            "success": vector_result["success"],
            "message": "PDF ì—…ë¡œë“œ ì™„ë£Œ",
            "file_id": file_id,
            "filename": file.filename,
            "vector_db_type": vector_service.current_db_type,  # ğŸ¯ ì‹¤ì œ ì‚¬ìš©ëœ DB
            "chunk_count": vector_result.get("chunk_count", 0),
            "auto_settings": {
                "chunk_size": auto_chunk_size,
                "chunk_overlap": auto_chunk_overlap,
                "pdf_loader": extraction_result["loader_used"],
                "language": analysis_result.language
            },
            "question_analysis": {
                "recommended_questions": await doc_service.calculate_optimal_question_count(
                    content=extraction_result["content"],
                    metadata=metadata
                ),
                "content_analysis": {
                    "total_sentences": extraction_result.get("total_sentences", 0),
                    "total_paragraphs": extraction_result.get("total_paragraphs", 0),
                    "key_concepts": extraction_result.get("key_concepts", []),
                    "complexity_score": extraction_result.get("complexity_score", 0)
                }
            },
            "performance_metrics": {
                "total_time": total_time,
                "analysis_time": analysis_time,
                "extraction_time": extraction_time,
                "vector_init_time": vector_init_time,
                "vector_store_time": vector_store_time,
                "vector_performance": vector_result.get("performance_metrics", {})
            }
        }

        if not vector_result["success"]:
            response_data["error"] = vector_result.get("error")

        logger.info(f"ğŸ‰ SUCCESS PDF ì—…ë¡œë“œ ì™„ë£Œ: {file.filename} -> {vector_service.current_db_type}")
        logger.info(f"â±ï¸ ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
        logger.info(f"ğŸ“Š ì„±ëŠ¥ ìš”ì•½: ë¶„ì„({analysis_time:.2f}s) + ì¶”ì¶œ({extraction_time:.2f}s) + ë²¡í„°í™”({vector_store_time:.2f}s)")

        return JSONResponse(content=response_data)

    except Exception as e:
        total_time = time.time() - total_start_time
        logger.error(f"ERROR PDF ì—…ë¡œë“œ ì‹¤íŒ¨: {e} (ì´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ)")
        raise HTTPException(status_code=500, detail=str(e))


# ğŸ”„ 2. ë²¡í„° DB ìŠ¤ìœ„ì¹­
@router.post("/vector-switch")
async def switch_vector_db(
    db_type: str = Form(..., description="ì „í™˜í•  ë²¡í„° DB íƒ€ì… (milvus/faiss)"),
    vector_service: VectorDBService = Depends(get_vector_service)
) -> JSONResponse:
    """
    ğŸ”„ ë²¡í„° DB íƒ€ì… ì „í™˜
    """
    try:
        logger.info(f"STEP_SWITCH ë²¡í„° DB ì „í™˜ ì‹œì‘: {db_type}")

        # ë²¡í„° DB ì „í™˜
        success = await vector_service.switch_vector_db(db_type)

        if success:
            # ì „í™˜ í›„ ìƒíƒœ ì¡°íšŒ
            status = await vector_service.get_vector_db_status()

            response_data = {
                "success": True,
                "message": f"{db_type.upper()} ë²¡í„° DBë¡œ ì „í™˜ ì™„ë£Œ",
                "current_db_type": status.get("current_db_type"),
                "document_count": status.get("current_db_health", {}).get("document_count", 0)
            }
        else:
            response_data = {
                "success": False,
                "message": f"{db_type.upper()} ë²¡í„° DB ì „í™˜ ì‹¤íŒ¨"
            }

        logger.info(f"SUCCESS ë²¡í„° DB ì „í™˜ ê²°ê³¼: {success}")
        return JSONResponse(content=response_data)

    except Exception as e:
        logger.error(f"ERROR ë²¡í„° DB ì „í™˜ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ğŸ“‹ 3. í˜„ì¬ ë²¡í„° DBì˜ ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ
@router.get("/all-documents")
async def get_all_documents(
    limit: int = Query(100, description="ì¡°íšŒí•  íŒŒì¼ ìˆ˜ ì œí•œ (ê¸°ë³¸: 100ê°œ íŒŒì¼)"),
    vector_service: VectorDBService = Depends(get_vector_service)
) -> JSONResponse:
    """
    ğŸ“‹ í˜„ì¬ ë²¡í„° DBì— ì €ì¥ëœ íŒŒì¼ ì¡°íšŒ (ìµœì‹ ìˆœ)
    - limit: ì¡°íšŒí•  íŒŒì¼ ê°œìˆ˜ ì œí•œ (ê¸°ë³¸: 100ê°œ íŒŒì¼)
    - íŒŒì¼ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í‘œì‹œ (ìµœì‹  ì—…ë¡œë“œìˆœ)
    """
    try:
        logger.info(f"STEP_DOCS íŒŒì¼ ì¡°íšŒ ì‹œì‘ (limit: {limit}ê°œ íŒŒì¼)")

        # limit ë²”ìœ„ ì œí•œ (1~1000 íŒŒì¼)
        actual_limit = max(1, min(limit, 1000))

        # íŒŒì¼ ì¡°íšŒ
        result = await vector_service.get_all_documents(actual_limit)

        if result["success"]:
            response_data = {
                "success": True,
                "message": "íŒŒì¼ ì¡°íšŒ ì™„ë£Œ",
                "vector_db_type": result["vector_db_type"],
                "total_documents": result["total_documents"],  # ì „ì²´ ì²­í¬ ìˆ˜
                "total_files": result["total_files"],  # ì‹¤ì œ ë°˜í™˜ëœ íŒŒì¼ ìˆ˜
                "all_files_count": result.get("all_files_count", 0),  # ì „ì²´ íŒŒì¼ ìˆ˜
                "limit_applied": result.get("limit_applied"),
                "files": result["files"]
            }
        else:
            response_data = {
                "success": False,
                "message": "íŒŒì¼ ì¡°íšŒ ì‹¤íŒ¨",
                "error": result.get("error")
            }

        logger.info(f"SUCCESS íŒŒì¼ ì¡°íšŒ ì™„ë£Œ: {result.get('total_files', 0)}ê°œ íŒŒì¼ ë°˜í™˜ (ì „ì²´ {result.get('all_files_count', 0)}ê°œ ì¤‘)")
        return JSONResponse(content=response_data)

    except Exception as e:
        logger.error(f"ERROR íŒŒì¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ğŸ” 4. í˜„ì¬ ë²¡í„° DB ìƒíƒœ ì¡°íšŒ (ë³´ë„ˆìŠ¤ - ë””ë²„ê¹…ìš©)
@router.get("/vector-status")
async def get_vector_db_status(
    vector_service: VectorDBService = Depends(get_vector_service)
) -> JSONResponse:
    """
    ğŸ” í˜„ì¬ ë²¡í„° DB ìƒíƒœ ì¡°íšŒ
    """
    try:
        status = await vector_service.get_vector_db_status()
        return JSONResponse(content=status)
    except Exception as e:
        logger.error(f"ERROR ë²¡í„° DB ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ğŸ’¥ 5. ë²¡í„° DB ëª¨ë“  ë°ì´í„° ì‚­ì œ (ìœ„í—˜í•œ ì‘ì—…)
@router.delete("/clear-all")
async def clear_all_documents(
    confirm_token: str = Form(..., description="ì‚­ì œ í™•ì¸ í† í°: CLEAR_ALL_CONFIRM"),
    vector_service: VectorDBService = Depends(get_vector_service)
) -> JSONResponse:
    """
    ğŸ’¥ ë²¡í„° DBì˜ ëª¨ë“  ë°ì´í„° ì‚­ì œ (ìœ„í—˜í•œ ì‘ì—…)

    âš ï¸ ì£¼ì˜: ì´ ì‘ì—…ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!
    confirm_tokenì— "CLEAR_ALL_CONFIRM"ì„ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.
    """
    try:
        logger.info("ğŸš¨ DANGER ë²¡í„° DB ì „ì²´ ì‚­ì œ ìš”ì²­")

        # ì „ì²´ ì‚­ì œ ì‹¤í–‰
        result = await vector_service.clear_all_documents(confirm_token)

        if result["success"]:
            response_data = {
                "success": True,
                "message": result["message"],
                "vector_db_type": result["vector_db_type"],
                "deleted_count": result.get("deleted_count", 0),
                "remaining_count": result.get("remaining_count", 0)
            }
            logger.info(f"SUCCESS ë²¡í„° DB ì „ì²´ ì‚­ì œ ì™„ë£Œ: {result.get('deleted_count', 0)}ê°œ ì‚­ì œ")
        else:
            response_data = {
                "success": False,
                "message": "ì „ì²´ ì‚­ì œ ì‹¤íŒ¨",
                "error": result.get("error"),
                "vector_db_type": result.get("vector_db_type")
            }

        return JSONResponse(content=response_data)

    except Exception as e:
        logger.error(f"ERROR ë²¡í„° DB ì „ì²´ ì‚­ì œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))
