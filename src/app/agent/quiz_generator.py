"""
ğŸ¤– Quiz Generation AI Agent using LangGraph
"""
import logging
import os
import asyncio
from typing import Dict, List, Any, Optional, TypedDict
from dataclasses import dataclass
from enum import Enum
import json
import time

# tokenizers ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
os.environ["TOKENIZERS_PARALLELISM"] = "false"

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langchain.prompts import ChatPromptTemplate

# ğŸ”¥ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ì ì„í¬íŠ¸
from .prompt import QuizPromptManager
from .prompt.quiz_prompt_manager import DifficultyLevel, QuestionType

logger = logging.getLogger(__name__)


@dataclass
class QuizRequest:
    """ë¬¸ì œ ìƒì„± ìš”ì²­"""
    file_ids: List[str]                 # ëŒ€ìƒ íŒŒì¼ IDë“¤
    num_questions: int = 5              # ìƒì„±í•  ë¬¸ì œ ìˆ˜
    difficulty: DifficultyLevel = DifficultyLevel.MEDIUM
    question_type: QuestionType = QuestionType.MULTIPLE_CHOICE
    custom_topic: Optional[str] = None  # íŠ¹ì • ì£¼ì œ ì§€ì •
    additional_instructions: Optional[List[str]] = None  # ì¶”ê°€ ì§€ì‹œì‚¬í•­


class QuizState(TypedDict):
    """LangGraph ìƒíƒœ ê´€ë¦¬"""
    # ì…ë ¥
    request: QuizRequest
    documents: List[Dict[str, Any]]

    # ì›Œí¬í”Œë¡œìš° ìƒíƒœ
    summary: str
    core_topics: List[str]
    keywords: List[str]
    generated_questions: List[Dict[str, Any]]

    # ë©”íƒ€ë°ì´í„°
    current_step: str
    errors: List[str]
    domain_context: Dict[str, Any]


class QuizGeneratorAgent:
    """ë¬¸ì œ ìƒì„± AI ì—ì´ì „íŠ¸"""

    def __init__(self, openai_api_key: Optional[str] = None):
        """
        ì´ˆê¸°í™”
        Args:
            openai_api_key: OpenAI API í‚¤ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ ë¡œë“œ ê°€ëŠ¥)
        """
        self.openai_api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        if not self.openai_api_key:
            raise ValueError("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ ì§ì ‘ ì „ë‹¬í•˜ì„¸ìš”.")

        # LLM ëª¨ë¸ ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",  # ë¹„ìš© íš¨ìœ¨ì ì¸ ëª¨ë¸
            temperature=0.7,      # ì°½ì˜ì„±ê³¼ ì¼ê´€ì„±ì˜ ê· í˜•
            api_key=self.openai_api_key if self.openai_api_key else None
        )

        # LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±
        self.workflow = self._create_workflow()

        # ğŸ¯ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ì ì´ˆê¸°í™”
        self.prompt_manager = QuizPromptManager()

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì´ˆê¸°í™”
        self.summary_template = ChatPromptTemplate.from_messages([
            ("system", "ë‹¹ì‹ ì€ ì „ë¬¸ êµìœ¡ ì»¨í…ì¸  ë¶„ì„ê°€ì…ë‹ˆë‹¤."),
            ("human", "{prompt}")
        ])

        self.topic_template = ChatPromptTemplate.from_messages([
            ("system", "ë‹¹ì‹ ì€ ì „ë¬¸ êµìœ¡ê³¼ì • ì„¤ê³„ìì…ë‹ˆë‹¤."),
            ("human", "{prompt}")
        ])

        self.keyword_template = ChatPromptTemplate.from_messages([
            ("system", "ë‹¹ì‹ ì€ ì „ë¬¸ ì‹œí—˜ ì¶œì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
            ("human", "{prompt}")
        ])

        self.question_template = ChatPromptTemplate.from_messages([
            ("system", "{system_message}"),
            ("human", "{prompt}")
        ])

        self.validation_template = ChatPromptTemplate.from_messages([
            ("system", "ë‹¹ì‹ ì€ ì „ë¬¸ êµìœ¡ ì»¨í…ì¸  í’ˆì§ˆ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
            ("human", "{prompt}")
        ])

        # ì²´ì¸ ì´ˆê¸°í™”
        self.summary_chain = self.summary_template | self.llm
        self.topic_chain = self.topic_template | self.llm
        self.keyword_chain = self.keyword_template | self.llm
        self.question_chain = self.question_template | self.llm
        self.validation_chain = self.validation_template | self.llm

    def _create_workflow(self):
        """LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        workflow = StateGraph(QuizState)

        # ë³‘ë ¬ ì²˜ë¦¬ ë…¸ë“œ ì¶”ê°€
        workflow.add_node("parallel_processor", self._parallel_process)
        workflow.add_node("question_generator", self._generate_questions)

        # ì›Œí¬í”Œë¡œìš° ìˆœì„œ ì •ì˜
        workflow.set_entry_point("parallel_processor")
        workflow.add_edge("parallel_processor", "question_generator")
        workflow.add_edge("question_generator", END)

        return workflow.compile()

    async def _parallel_process(self, state: QuizState) -> QuizState:
        """ğŸ“„ ë³‘ë ¬ ì²˜ë¦¬: ë¬¸ì„œ ìš”ì•½, í•µì‹¬ ì£¼ì œ ì¶”ì¶œ, í‚¤ì›Œë“œ ì¶”ì¶œ"""
        try:
            parallel_start = time.time()
            logger.info("ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘")

            # ë¬¸ì„œ ë‚´ìš© ê²°í•© ë° ì „ì²˜ë¦¬
            combined_content = ""
            domain_info = {}
            total_sentences = 0
            total_paragraphs = 0

            for doc in state["documents"]:
                filename = doc.get("filename", "Unknown")
                content = doc.get("content", "")

                # ë¬¸ì¥ê³¼ ë‹¨ë½ ìˆ˜ ê³„ì‚°
                sentences = [s.strip() for s in content.split('.') if s.strip()]
                paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
                total_sentences += len(sentences)
                total_paragraphs += len(paragraphs)

                combined_content += f"\n\n=== {filename} ===\n{content}"
                domain_info[filename] = {
                    "language": doc.get("language", "unknown"),
                    "file_size": doc.get("file_size", 0),
                    "chunk_count": doc.get("total_chunks", 0),
                    "sentence_count": len(sentences),
                    "paragraph_count": len(paragraphs)
                }

            # ë¬¸ì œ ìˆ˜ ì¬ê³„ì‚°
            base_questions = max(3, total_sentences // 4)  # 4ë¬¸ì¥ë‹¹ 1ë¬¸ì œ
            complexity_factor = min(1.5, 1 + (total_paragraphs / total_sentences))
            concept_factor = min(0.5, len(domain_info) * 0.1)

            recommended_questions = int(base_questions * complexity_factor * (1 + concept_factor))
            recommended_questions = min(max(5, recommended_questions), 20)  # 5-20ê°œ ì‚¬ì´ë¡œ ì œí•œ

            # ë¬¸ì œ ìˆ˜ ì—…ë°ì´íŠ¸
            state["request"].num_questions = recommended_questions

            # ë³‘ë ¬ ì²˜ë¦¬ íƒœìŠ¤í¬ ì •ì˜
            async def summarize_documents():
                summary_prompt = self.prompt_manager.get_prompt("summary").format(
                    content=combined_content
                )
                return await self.summary_chain.ainvoke({"prompt": summary_prompt})

            async def extract_topics():
                topic_prompt = self.prompt_manager.get_prompt("topic").format(
                    content=combined_content,
                    difficulty=state["request"].difficulty.value,
                    num_questions=recommended_questions,
                    question_type=state["request"].question_type.value,
                    num_topics=recommended_questions + 3
                )
                return await self.topic_chain.ainvoke({"prompt": topic_prompt})

            async def extract_keywords():
                keyword_prompt = self.prompt_manager.get_prompt("keyword").format(
                    content=combined_content,
                    difficulty=state["request"].difficulty.value,
                    question_type=state["request"].question_type.value,
                    num_keywords=recommended_questions * 3
                )
                return await self.keyword_chain.ainvoke({"prompt": keyword_prompt})

            # ë³‘ë ¬ ì‹¤í–‰
            topics_response, summary_response, keywords_response = await asyncio.gather(
                extract_topics(), summarize_documents(), extract_keywords()
            )
            logger.info(f"[ì „ì²˜ë¦¬] ë³‘ë ¬ ì „ì²´ ì†Œìš” ì‹œê°„: {time.time() - parallel_start:.2f}ì´ˆ")
            summary = summary_response.content
            topics = [line.strip().lstrip('- â€¢').strip() for line in topics_response.content.split('\n') if line.strip().startswith(('-', 'â€¢'))]
            keywords = [kw.strip() for kw in keywords_response.content.split(',') if kw.strip()]
            logger.info(f"[ì „ì²˜ë¦¬] ì™„ë£Œ (ì´ ì†Œìš” ì‹œê°„: {time.time() - parallel_start:.2f}ì´ˆ)")

            # ìƒíƒœ ì—…ë°ì´íŠ¸
            state["summary"] = summary
            state["core_topics"] = topics
            state["keywords"] = keywords
            state["domain_context"] = {
                **domain_info,
                "total_sentences": total_sentences,
                "total_paragraphs": total_paragraphs,
                "recommended_questions": recommended_questions
            }
            state["current_step"] = "parallel_processor"

            logger.info(f"SUCCESS ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ: {recommended_questions}ê°œ ë¬¸ì œ ì¶”ì²œ")
            return state

        except Exception as e:
            logger.error(f"ERROR ë³‘ë ¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            state["errors"].append(f"ë³‘ë ¬ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return state

    async def _generate_questions(self, state: QuizState) -> QuizState:
        """â“ 4ë‹¨ê³„: ë‹¤ì–‘ì„±ê³¼ í’ˆì§ˆì„ ê³ ë ¤í•œ ìµœì í™”ëœ ë³‘ë ¬ ë°°ì¹˜ ë¬¸ì œ ìƒì„±"""
        try:
            generate_start = time.time()
            logger.info("STEP4 ë‹¤ì–‘ì„±ê³¼ í’ˆì§ˆì„ ê³ ë ¤í•œ ìµœì í™”ëœ ë³‘ë ¬ ë°°ì¹˜ ë¬¸ì œ ìƒì„± ì‹œì‘")

            request = state["request"]
            summary = state["summary"]
            topics = state["core_topics"]
            keywords = state["keywords"]

            # ì¶”ê°€ ì§€ì‹œì‚¬í•­ì´ ìˆëŠ” ê²½ìš° í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
            additional_guide = ""
            if request.additional_instructions:
                additional_guide = "\n\nğŸ“ **ì¶”ê°€ ì§€ì‹œì‚¬í•­**:\n" + "\n".join(f"- {instruction}" for instruction in request.additional_instructions)

            # ğŸ¯ ìµœì í™”ëœ ë°°ì¹˜ í¬ê¸° ê³„ì‚° (ë” ì‘ì€ ë°°ì¹˜ë¡œ ë‹¤ì–‘ì„± í™•ë³´)
            target_questions = request.num_questions
            batch_size = min(2, max(1, target_questions // 3))  # 1-2ê°œì”© ë°°ì¹˜ë¡œ ë‹¤ì–‘ì„± í™•ë³´
            num_batches = (target_questions + batch_size - 1) // batch_size

            logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •: {num_batches}ê°œ ë°°ì¹˜, ë°°ì¹˜ë‹¹ {batch_size}ê°œ ë¬¸ì œ")

            # ğŸ¯ í‚¤ì›Œë“œ ë¶„ì‚° ì „ëµ
            keyword_groups = self._distribute_keywords(keywords, num_batches)
            topic_groups = self._distribute_topics(topics, num_batches)

            # ğŸš€ ë³‘ë ¬ ë°°ì¹˜ ìƒì„± í•¨ìˆ˜
            async def generate_batch(batch_num: int, batch_size: int, is_final_batch: bool = False) -> List[Dict]:
                """ë‹¨ì¼ ë°°ì¹˜ ë¬¸ì œ ìƒì„± (ë‹¤ì–‘ì„± ê³ ë ¤)"""
                try:
                    # ë§ˆì§€ë§‰ ë°°ì¹˜ëŠ” ë‚¨ì€ ë¬¸ì œ ìˆ˜ë§Œí¼ë§Œ ìƒì„±
                    actual_batch_size = batch_size
                    if is_final_batch:
                        remaining = target_questions - (batch_num * batch_size)
                        actual_batch_size = max(1, remaining)

                    # ë°°ì¹˜ë³„ í‚¤ì›Œë“œì™€ ì£¼ì œ í• ë‹¹
                    batch_keywords = keyword_groups[batch_num % len(keyword_groups)]
                    batch_topics = topic_groups[batch_num % len(topic_groups)]

                    # ë°°ì¹˜ë³„ ë‹¤ì–‘í•œ ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ ë¬¸ì œ ìƒì„±
                    batch_prompts = []

                    # ë‚œì´ë„ë³„ ë¬¸ì œ ìƒì„± ì „ëµ
                    if batch_num < num_batches * 0.4:  # 40% ê¸°ë³¸ ê°œë…
                        batch_prompts.append({
                            "type": "basic_concept",
                            "prompt": self._create_diversity_prompt(
                                summary, batch_topics, batch_keywords,
                                actual_batch_size, request, "basic"
                            ),
                            "system": "ë‹¹ì‹ ì€ ê¸°ë³¸ ê°œë… ë¬¸ì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•µì‹¬ ê°œë…ì„ ëª…í™•í•˜ê²Œ ë¬»ëŠ” ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”. ì¤‘ë³µì„ í”¼í•˜ê³  ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì ‘ê·¼í•˜ì„¸ìš”."
                        })
                    elif batch_num < num_batches * 0.7:  # 30% ê°œë… ì—°ê³„
                        batch_prompts.append({
                            "type": "concept_integration",
                            "prompt": self._create_diversity_prompt(
                                summary, batch_topics, batch_keywords,
                                actual_batch_size, request, "concept"
                            ),
                            "system": "ë‹¹ì‹ ì€ ê°œë… ì—°ê³„ ë¬¸ì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì—¬ëŸ¬ ê°œë…ì„ ì—°ê²°í•˜ëŠ” ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”. ë‹¤ì–‘í•œ ì˜ˆì‹œì™€ ì‘ìš©ì„ í¬í•¨í•˜ì„¸ìš”."
                        })
                    else:  # 30% ì‘ìš© ë¬¸ì œ
                        batch_prompts.append({
                            "type": "application",
                            "prompt": self._create_diversity_prompt(
                                summary, batch_topics, batch_keywords,
                                actual_batch_size, request, "application"
                            ),
                            "system": "ë‹¹ì‹ ì€ ì‘ìš© ë¬¸ì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‹¤ì œ ìƒí™©ì— ì ìš©í•˜ëŠ” ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”. êµ¬ì²´ì ì¸ ì‚¬ë¡€ì™€ ë¶„ì„ì„ í¬í•¨í•˜ì„¸ìš”."
                        })

                    # ë°°ì¹˜ ë‚´ì—ì„œë„ ë³‘ë ¬ ì²˜ë¦¬ (ì—¬ëŸ¬ ì ‘ê·¼ ë°©ì‹)
                    batch_tasks = []
                    for prompt_info in batch_prompts:
                        task = self.question_chain.ainvoke({
                            "system_message": prompt_info["system"],
                            "prompt": prompt_info["prompt"]
                        })
                        batch_tasks.append(task)

                    # ë°°ì¹˜ ë³‘ë ¬ ì‹¤í–‰
                    batch_responses = await asyncio.gather(*batch_tasks, return_exceptions=True)

                    # ì‘ë‹µ ì²˜ë¦¬ ë° íŒŒì‹±
                    batch_questions = []
                    for i, response in enumerate(batch_responses):
                        if isinstance(response, Exception):
                            logger.warning(f"ë°°ì¹˜ {batch_num} ì‘ë‹µ {i} ì‹¤íŒ¨: {response}")
                            continue

                        try:
                            if hasattr(response, 'content') and isinstance(response.content, str):
                                questions = self._parse_questions(response.content)
                                # ë°°ì¹˜ë³„ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                                for q in questions:
                                    q["batch_num"] = batch_num
                                    q["difficulty_level"] = batch_prompts[i]["type"]
                                batch_questions.extend(questions)
                        except Exception as e:
                            logger.warning(f"ë°°ì¹˜ {batch_num} íŒŒì‹± ì‹¤íŒ¨: {e}")
                            continue

                    logger.info(f"ë°°ì¹˜ {batch_num} ì™„ë£Œ: {len(batch_questions)}ê°œ ë¬¸ì œ ìƒì„±")
                    return batch_questions

                except Exception as e:
                    logger.error(f"ë°°ì¹˜ {batch_num} ìƒì„± ì‹¤íŒ¨: {e}")
                    return []

            # ğŸš€ ëª¨ë“  ë°°ì¹˜ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰
            batch_tasks = []
            for i in range(num_batches):
                is_final = (i == num_batches - 1)
                task = generate_batch(i, batch_size, is_final)
                batch_tasks.append(task)

            # ë³‘ë ¬ ì‹¤í–‰
            all_batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)

            # ğŸ“Š ëª¨ë“  ë°°ì¹˜ ê²°ê³¼ í†µí•©
            all_questions = []
            for i, batch_result in enumerate(all_batch_results):
                if isinstance(batch_result, Exception):
                    logger.error(f"ë°°ì¹˜ {i} ì „ì²´ ì‹¤íŒ¨: {batch_result}")
                    continue
                if isinstance(batch_result, list):
                    all_questions.extend(batch_result)

            logger.info(f"ëª¨ë“  ë°°ì¹˜ ì™„ë£Œ: ì´ {len(all_questions)}ê°œ ë¬¸ì œ ìƒì„±")

            # ğŸ”„ ê³ ê¸‰ ì¤‘ë³µ ì œê±° ë° í’ˆì§ˆ ê²€ì‚¬ (ë” ì—„ê²©í•œ ê¸°ì¤€)
            final_questions = self._advanced_quality_check_with_diversity(all_questions, target_questions)

            # ë¬¸ì œ ìˆ˜ê°€ ë¶€ì¡±í•œ ê²½ìš° ë¹ ë¥¸ ë³´ì¶© ìƒì„± (ë‹¤ì–‘ì„± ê³ ë ¤)
            if len(final_questions) < target_questions:
                logger.info(f"ë¬¸ì œ ìˆ˜ ë¶€ì¡± ({len(final_questions)}/{target_questions}), ë‹¤ì–‘ì„± ê³ ë ¤í•œ ë³´ì¶© ìƒì„±")

                # ì‚¬ìš©ë˜ì§€ ì•Šì€ í‚¤ì›Œë“œì™€ ì£¼ì œë¡œ ë³´ì¶© ìƒì„±
                used_keywords = set()
                used_topics = set()
                for q in final_questions:
                    question_text = q.get("question", "").lower()
                    for keyword in keywords:
                        if keyword.lower() in question_text:
                            used_keywords.add(keyword)
                    for topic in topics:
                        if topic.lower() in question_text:
                            used_topics.add(topic)

                unused_keywords = [k for k in keywords if k not in used_keywords]
                unused_topics = [t for t in topics if t not in used_topics]

                supplement_prompt = self._create_diversity_prompt(
                    summary, unused_topics[:3], unused_keywords[:5],
                    target_questions - len(final_questions), request, "mixed"
                )

                try:
                    supplement_response = await self.question_chain.ainvoke({
                        "system_message": "ë‹¤ì–‘ì„±ê³¼ í’ˆì§ˆì„ ì¤‘ì‹œí•˜ëŠ” ë¬¸ì œ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì¤‘ë³µì„ í”¼í•˜ê³  ìƒˆë¡œìš´ ê´€ì ì—ì„œ ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”.",
                        "prompt": supplement_prompt
                    })

                    supplement_questions = self._parse_questions(supplement_response.content)
                    supplement_questions = self._basic_quality_check(supplement_questions)

                    final_questions.extend(supplement_questions)
                    logger.info(f"ë³´ì¶© ìƒì„± ì™„ë£Œ: {len(supplement_questions)}ê°œ ì¶”ê°€")

                except Exception as e:
                    logger.warning(f"ë³´ì¶© ìƒì„± ì‹¤íŒ¨: {e}")

            # ìµœì¢… ì¤‘ë³µ ì œê±° ë° í’ˆì§ˆ ê²€ì‚¬
            final_questions = self._advanced_quality_check_with_diversity(final_questions, target_questions)

            # ì •í™•íˆ ìš”ì²­ëœ ìˆ˜ë§Œí¼ë§Œ ë°˜í™˜
            final_questions = final_questions[:target_questions]

            # ID ìˆœì°¨ì ìœ¼ë¡œ ë¶€ì—¬
            for i, question in enumerate(final_questions, 1):
                question["id"] = i

            state["generated_questions"] = final_questions
            state["current_step"] = "question_generator"

            # ğŸ“Š ë¶„í¬ í™•ì¸ ë¡œê¹…
            basic_count = sum(1 for q in final_questions if q.get("difficulty_level") == "basic_concept")
            concept_count = sum(1 for q in final_questions if q.get("difficulty_level") == "concept_integration")
            app_count = sum(1 for q in final_questions if q.get("difficulty_level") == "application")

            logger.info(f"SUCCESS ë‹¤ì–‘ì„±ê³¼ í’ˆì§ˆì„ ê³ ë ¤í•œ ë¬¸ì œ ìƒì„± ì™„ë£Œ: ì´ {len(final_questions)}ê°œ")
            logger.info(f"- ê¸°ë³¸ ê°œë…: {basic_count}ê°œ")
            logger.info(f"- ê°œë… ì—°ê³„: {concept_count}ê°œ")
            logger.info(f"- ì‘ìš© ë¬¸ì œ: {app_count}ê°œ")
            logger.info(f"[ì‹¤í–‰ì‹œê°„] ìµœì í™”ëœ ë¬¸ì œ ìƒì„± ì†Œìš” ì‹œê°„: {time.time() - generate_start:.2f}ì´ˆ")

            return state

        except Exception as e:
            logger.error(f"ERROR ìµœì í™”ëœ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")
            state["errors"].append(f"ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return state

    def _distribute_keywords(self, keywords: List[str], num_batches: int) -> List[List[str]]:
        """í‚¤ì›Œë“œë¥¼ ë°°ì¹˜ë³„ë¡œ ë¶„ì‚° ë°°ì¹˜"""
        if not keywords:
            return [[] for _ in range(num_batches)]

        # í‚¤ì›Œë“œë¥¼ ê·¸ë£¹ë³„ë¡œ ë¶„ì‚°
        keyword_groups = []
        for i in range(num_batches):
            start_idx = (i * len(keywords)) // num_batches
            end_idx = ((i + 1) * len(keywords)) // num_batches
            group = keywords[start_idx:end_idx]
            if not group and keywords:  # ë¹ˆ ê·¸ë£¹ì¸ ê²½ìš° ì „ì²´ í‚¤ì›Œë“œ ì‚¬ìš©
                group = keywords
            keyword_groups.append(group)

        return keyword_groups

    def _distribute_topics(self, topics: List[str], num_batches: int) -> List[List[str]]:
        """ì£¼ì œë¥¼ ë°°ì¹˜ë³„ë¡œ ë¶„ì‚° ë°°ì¹˜"""
        if not topics:
            return [[] for _ in range(num_batches)]

        # ì£¼ì œë¥¼ ê·¸ë£¹ë³„ë¡œ ë¶„ì‚°
        topic_groups = []
        for i in range(num_batches):
            start_idx = (i * len(topics)) // num_batches
            end_idx = ((i + 1) * len(topics)) // num_batches
            group = topics[start_idx:end_idx]
            if not group and topics:  # ë¹ˆ ê·¸ë£¹ì¸ ê²½ìš° ì „ì²´ ì£¼ì œ ì‚¬ìš©
                group = topics
            topic_groups.append(group)

        return topic_groups

    def _create_diversity_prompt(self, summary: str, topics: List[str], keywords: List[str],
                                num_questions: int, request: QuizRequest, difficulty_type: str) -> str:
        """ë‹¤ì–‘ì„±ì„ ê³ ë ¤í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""

        # ë‚œì´ë„ë³„ íŠ¹í™” ì§€ì‹œì‚¬í•­
        difficulty_instructions = {
            "basic": "ê¸°ë³¸ ê°œë…ì„ ëª…í™•í•˜ê²Œ ë¬»ëŠ” ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”. í•µì‹¬ ìš©ì–´ì™€ ì •ì˜ì— ì§‘ì¤‘í•˜ì„¸ìš”.",
            "concept": "ì—¬ëŸ¬ ê°œë…ì„ ì—°ê²°í•˜ëŠ” ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”. ê°œë… ê°„ì˜ ê´€ê³„ì™€ ë¹„êµë¥¼ í¬í•¨í•˜ì„¸ìš”.",
            "application": "ì‹¤ì œ ìƒí™©ì— ì ìš©í•˜ëŠ” ë¬¸ì œë¥¼ ìƒì„±í•˜ì„¸ìš”. êµ¬ì²´ì ì¸ ì‚¬ë¡€ì™€ ë¶„ì„ì„ í¬í•¨í•˜ì„¸ìš”.",
            "mixed": "ë‹¤ì–‘í•œ ë‚œì´ë„ì˜ ë¬¸ì œë¥¼ ê· í˜•ìˆê²Œ ìƒì„±í•˜ì„¸ìš”."
        }

        # ì¤‘ë³µ ë°©ì§€ ì§€ì‹œì‚¬í•­
        diversity_instruction = """
âš ï¸ **ì¤‘ë³µ ë°©ì§€ ì§€ì¹¨**:
- ê°™ì€ í‚¤ì›Œë“œë‚˜ ì£¼ì œë¥¼ ë°˜ë³µí•´ì„œ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ë¹„ìŠ·í•œ ì§ˆë¬¸ í˜•ì‹ì„ í”¼í•˜ì„¸ìš”
- ë‹¤ì–‘í•œ ê´€ì ê³¼ ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ê° ë¬¸ì œëŠ” ë…ë¦½ì ì´ê³  ê³ ìœ í•´ì•¼ í•©ë‹ˆë‹¤
"""

        return self.prompt_manager.get_prompt("question").format(
            summary=summary,
            topics="\n".join(f"- {topic}" for topic in topics),
            keywords="\n".join(f"- {keyword}" for keyword in keywords),
            num_questions=num_questions,
            difficulty=request.difficulty.value,
            question_type=request.question_type.value
        ) + f"\n\n{difficulty_instructions.get(difficulty_type, '')}\n{diversity_instruction}"

    def _advanced_quality_check_with_diversity(self, questions: List[Dict], target_count: int) -> List[Dict]:
        """ë‹¤ì–‘ì„±ì„ ê³ ë ¤í•œ ê³ ê¸‰ í’ˆì§ˆ ê²€ì‚¬ ë° ì¤‘ë³µ ì œê±°"""
        if not questions:
            return []

        # 1ë‹¨ê³„: ê¸°ë³¸ í’ˆì§ˆ ê²€ì‚¬
        valid_questions = self._basic_quality_check(questions)

        if len(valid_questions) <= target_count:
            return valid_questions

        # 2ë‹¨ê³„: ê³ ê¸‰ ì¤‘ë³µ ì œê±° (ë” ì—„ê²©í•œ ê¸°ì¤€)
        unique_questions = []
        seen_questions = set()
        keyword_usage = {}  # í‚¤ì›Œë“œ ì‚¬ìš© ë¹ˆë„ ì¶”ì 

        for q in valid_questions:
            question_text = q["question"].lower().strip()

            # ë” ì—„ê²©í•œ ì¤‘ë³µ ê²€ì‚¬ (ìœ ì‚¬ë„ ê¸°ì¤€ ìƒí–¥)
            is_duplicate = False
            for seen in seen_questions:
                if self._calculate_similarity(question_text, seen) > 0.8:  # ë” ì—„ê²©í•œ ê¸°ì¤€
                    is_duplicate = True
                    break

            # í‚¤ì›Œë“œ ì¤‘ë³µ ê²€ì‚¬
            if not is_duplicate:
                question_keywords = self._extract_keywords_from_question(question_text)
                keyword_overlap = 0
                for keyword in question_keywords:
                    if keyword_usage.get(keyword, 0) >= 2:  # ê°™ì€ í‚¤ì›Œë“œê°€ 2ë²ˆ ì´ìƒ ì‚¬ìš©ëœ ê²½ìš°
                        keyword_overlap += 1

                # í‚¤ì›Œë“œ ì¤‘ë³µì´ ë„ˆë¬´ ë§ì€ ê²½ìš° ì œì™¸
                if keyword_overlap > len(question_keywords) * 0.5:  # 50% ì´ìƒ ì¤‘ë³µ
                    continue

            if not is_duplicate:
                unique_questions.append(q)
                seen_questions.add(question_text)

                # í‚¤ì›Œë“œ ì‚¬ìš© ë¹ˆë„ ì—…ë°ì´íŠ¸
                for keyword in self._extract_keywords_from_question(question_text):
                    keyword_usage[keyword] = keyword_usage.get(keyword, 0) + 1

                # ëª©í‘œ ìˆ˜ì— ë„ë‹¬í•˜ë©´ ì¤‘ë‹¨
                if len(unique_questions) >= target_count:
                    break

        # 3ë‹¨ê³„: í’ˆì§ˆ ì ìˆ˜ ê¸°ë°˜ ì •ë ¬ (ë‹¤ì–‘ì„± ê°€ì¤‘ì¹˜ ì¶”ê°€)
        scored_questions = []
        for q in unique_questions:
            score = self._calculate_question_score_with_diversity(q, keyword_usage)
            scored_questions.append((score, q))

        # ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        scored_questions.sort(key=lambda x: x[0], reverse=True)

        # ìƒìœ„ ë¬¸ì œë“¤ë§Œ ë°˜í™˜
        final_questions = [q for _, q in scored_questions[:target_count]]

        logger.info(f"ë‹¤ì–‘ì„±ì„ ê³ ë ¤í•œ ê³ ê¸‰ í’ˆì§ˆ ê²€ì‚¬ ì™„ë£Œ: {len(questions)}ê°œ â†’ {len(final_questions)}ê°œ")

        return final_questions

    def _extract_keywords_from_question(self, question_text: str) -> List[str]:
        """ë¬¸ì œì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP ì‚¬ìš© ê°€ëŠ¥)
        words = question_text.split()
        # 3ê¸€ì ì´ìƒì˜ ë‹¨ì–´ë§Œ í‚¤ì›Œë“œë¡œ ê°„ì£¼
        keywords = [word for word in words if len(word) >= 3]
        return keywords[:5]  # ìƒìœ„ 5ê°œë§Œ ë°˜í™˜

    def _calculate_question_score_with_diversity(self, question: Dict, keyword_usage: Dict[str, int]) -> float:
        """ë‹¤ì–‘ì„±ì„ ê³ ë ¤í•œ ë¬¸ì œ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        score = self._calculate_question_score(question)

        # ë‹¤ì–‘ì„± ë³´ë„ˆìŠ¤
        question_text = question.get("question", "").lower()
        question_keywords = self._extract_keywords_from_question(question_text)

        # ì‚¬ìš© ë¹ˆë„ê°€ ë‚®ì€ í‚¤ì›Œë“œì— ë³´ë„ˆìŠ¤
        diversity_bonus = 0
        for keyword in question_keywords:
            usage_count = keyword_usage.get(keyword, 0)
            if usage_count == 0:
                diversity_bonus += 0.3  # ìƒˆë¡œìš´ í‚¤ì›Œë“œ
            elif usage_count == 1:
                diversity_bonus += 0.1  # í•œ ë²ˆë§Œ ì‚¬ìš©ëœ í‚¤ì›Œë“œ

        score += diversity_bonus

        return score

    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚° (ê°œì„ ëœ ë²„ì „)"""
        from difflib import SequenceMatcher

        # ê¸°ë³¸ ìœ ì‚¬ë„
        basic_similarity = SequenceMatcher(None, text1, text2).ratio()

        # í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ë„
        words1 = set(text1.split())
        words2 = set(text2.split())

        if not words1 or not words2:
            return basic_similarity

        # Jaccard ìœ ì‚¬ë„
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        jaccard_similarity = intersection / union if union > 0 else 0

        # ê°€ì¤‘ í‰ê· 
        return (basic_similarity * 0.7) + (jaccard_similarity * 0.3)

    def _calculate_question_score(self, question: Dict) -> float:
        """ë¬¸ì œ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0

        # ê¸°ë³¸ ì ìˆ˜
        score += 1.0

        # ë¬¸ì œ ê¸¸ì´ ì ìˆ˜ (ì ì ˆí•œ ê¸¸ì´)
        question_length = len(question.get("question", ""))
        if 50 <= question_length <= 200:
            score += 0.5
        elif 30 <= question_length <= 300:
            score += 0.3

        # ì„ íƒì§€ ê°œìˆ˜ ì ìˆ˜
        options_count = len(question.get("options", []))
        if options_count == 4:
            score += 0.3
        elif options_count >= 3:
            score += 0.2

        # ì„¤ëª… ê¸¸ì´ ì ìˆ˜
        explanation_length = len(question.get("explanation", ""))
        if 20 <= explanation_length <= 150:
            score += 0.2

        # ë¬¸ì œ ìˆ˜ì¤€ ì ìˆ˜
        level = question.get("problem_level", "basic")
        if level == "application":
            score += 0.3
        elif level == "concept":
            score += 0.2

        return score

    def _basic_quality_check(self, questions: List[Dict]) -> List[Dict]:
        """ê¸°ë³¸ì ì¸ í’ˆì§ˆ ê²€ì‚¬ ìˆ˜í–‰"""
        valid_questions = []
        seen_questions = set()

        for q in questions:
            try:
                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                if not all(k in q for k in ["question", "options", "correct_answer", "explanation"]):
                    continue

                # ì¤‘ë³µ ë¬¸ì œ ì œê±° (ìœ ì‚¬ë„ ê¸°ë°˜, ê¸°ì¤€ ì™„í™”)
                question_text = q["question"].lower().strip()
                if any(self._is_similar(question_text, seen, threshold=0.9) for seen in seen_questions):  # ìœ ì‚¬ë„ ê¸°ì¤€ ìƒí–¥
                    continue
                seen_questions.add(question_text)

                # ì„ íƒì§€ ê²€ì¦ (ìµœì†Œ 2ê°œ ì´ìƒ)
                if len(q["options"]) < 2:
                    continue

                # ì •ë‹µì´ ì„ íƒì§€ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ì „ì²˜ë¦¬ëœ í˜•ì‹ ê³ ë ¤)
                correct_answer = q["correct_answer"]
                options = q["options"]

                # ì •ë‹µì´ ì„ íƒì§€ì— ì§ì ‘ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                if correct_answer in options:
                    pass
                else:
                    # ì •ë‹µì—ì„œ ë²ˆí˜¸ë¥¼ ì œê±°í•˜ê³  ë‚´ìš©ë§Œ ë¹„êµ
                    import re
                    answer_content = re.sub(r'^\d+\.\s*', '', correct_answer)
                    found = False
                    for option in options:
                        option_content = re.sub(r'^\d+\.\s*', '', option)
                        if answer_content == option_content:
                            found = True
                            break
                    if not found:
                        continue

                # ë¬¸ì œ ìˆ˜ì¤€ ì„¤ì •
                if "problem_level" not in q:
                    q["problem_level"] = "basic"

                valid_questions.append(q)
            except Exception as e:
                logger.warning(f"ë¬¸ì œ í’ˆì§ˆ ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue

        return valid_questions

    def _is_similar(self, text1: str, text2: str, threshold: float = 0.9) -> bool:
        """ë‘ í…ìŠ¤íŠ¸ì˜ ìœ ì‚¬ë„ ê²€ì‚¬ (ê¸°ì¤€ ìƒí–¥)"""
        from difflib import SequenceMatcher
        return SequenceMatcher(None, text1, text2).ratio() > threshold

    def _parse_questions(self, content: str) -> List[Dict]:
        """JSON ì‘ë‹µ íŒŒì‹±"""
        try:
            if "```json" in content:
                json_start = content.find("```json") + 7
                json_end = content.find("```", json_start)
                json_content = content[json_start:json_end].strip()
            elif "```" in content:
                json_start = content.find("```") + 3
                json_end = content.find("```", json_start)
                json_content = content[json_start:json_end].strip()
            else:
                json_content = content.strip()

            questions_data = json.loads(json_content)
            questions = questions_data.get("questions", [])

            # ì „ì²˜ë¦¬ ì ìš©
            return self._preprocess_questions(questions)

        except json.JSONDecodeError as e:
            logger.error(f"ERROR JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.error(f"LLM ì‘ë‹µ ë‚´ìš©: {content[:500]}...")
            return []

    def _preprocess_questions(self, questions: List[Dict]) -> List[Dict]:
        """ë¬¸ì œ ì‘ë‹µ ì „ì²˜ë¦¬ - ì„ íƒì§€ ë²ˆí˜¸ ì¤‘ë³µ ë° ì •ë‹µ ë²ˆí˜¸ ìˆ˜ì •"""
        processed_questions = []

        for question in questions:
            processed_question = question.copy()

            # ì„ íƒì§€ ì „ì²˜ë¦¬
            if isinstance(question.get("options"), list):
                processed_options = []
                for option in question["options"]:
                    # ë²ˆí˜¸ ì¤‘ë³µ ì œê±° (ì˜ˆ: "1. 1. ë‚´ìš©" -> "1. ë‚´ìš©")
                    if isinstance(option, str):
                        # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ë²ˆí˜¸ ì¤‘ë³µ íŒ¨í„´ ì°¾ê¸°
                        import re
                        # "ìˆ«ì. ìˆ«ì. ë‚´ìš©" íŒ¨í„´ì„ "ìˆ«ì. ë‚´ìš©"ìœ¼ë¡œ ë³€ê²½
                        cleaned_option = re.sub(r'^(\d+)\.\s*\1\.\s*', r'\1. ', option)
                        processed_options.append(cleaned_option)
                    else:
                        processed_options.append(option)

                processed_question["options"] = processed_options

                # correct_answer_number ìˆ˜ì •
                if "correct_answer" in question:
                    correct_answer = question["correct_answer"]
                    # correct_answerì—ì„œ ë²ˆí˜¸ ì¶”ì¶œ
                    import re
                    match = re.match(r'^(\d+)\.\s*(.+)', correct_answer)
                    if match:
                        answer_number = int(match.group(1))
                        answer_content = match.group(2).strip()
                        processed_question["correct_answer"] = f"{answer_number}. {answer_content}"
                        processed_question["correct_answer_number"] = answer_number
                    else:
                        # correct_answerê°€ ì˜¬ë°”ë¥¸ í˜•ì‹ì´ ì•„ë‹Œ ê²½ìš°, ì˜µì…˜ì—ì„œ ì°¾ê¸°
                        for i, option in enumerate(processed_options, 1):
                            # ì˜µì…˜ì—ì„œ ë²ˆí˜¸ ì œê±° í›„ ë‚´ìš©ë§Œ ë¹„êµ
                            option_content = re.sub(r'^\d+\.\s*', '', option)
                            if option_content == correct_answer or option_content in correct_answer:
                                processed_question["correct_answer"] = f"{i}. {option_content}"
                                processed_question["correct_answer_number"] = i
                                break
                        else:
                            # ì°¾ì§€ ëª»í•œ ê²½ìš° ì²« ë²ˆì§¸ ì˜µì…˜ì„ ì •ë‹µìœ¼ë¡œ ì„¤ì •
                            if processed_options:
                                first_option = processed_options[0]
                                first_content = re.sub(r'^\d+\.\s*', '', first_option)
                                processed_question["correct_answer"] = f"1. {first_content}"
                                processed_question["correct_answer_number"] = 1

            processed_questions.append(processed_question)

        return processed_questions

    def smart_truncate(self, text, max_length=2000):
        """ì•/ì¤‘ê°„/ë ìƒ˜í”Œë§ ë°©ì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ìë¦„"""
        if len(text) <= max_length:
            return text
        part = max_length // 3
        return text[:part] + text[len(text)//2:len(text)//2+part] + text[-part:]

    async def generate_quiz(self, request: QuizRequest, documents: List[Dict[str, Any]], use_combined_prompt: bool = False, use_sampling: bool = False) -> Dict[str, Any]:
        """
        ë¬¸ì œ ìƒì„± ë©”ì¸ ë©”ì„œë“œ (ë¬¸ì„œë³„ ì „ì²˜ë¦¬ê¹Œì§€ ì™„ì „ ë¹„ë™ê¸° + ë¬¸ì œ ìƒì„± 2ë¬¸ì œì”© ë³‘ë ¬)
        use_combined_prompt: ë¬´ì‹œ(í•­ìƒ ë¶„ë¦¬ ë°©ì‹)
        use_sampling: Trueë©´ ìƒ˜í”Œë§(ì•/ì¤‘ê°„/ë), Falseë©´ ì „ì²´ ê²°í•©
        """
        import time
        try:
            total_start = time.time()
            logger.info(f"ğŸš€ ë¬¸ì œ ìƒì„± AI ì—ì´ì „íŠ¸ ì‹œì‘ (ë¬¸ì„œë³„ ì „ì²˜ë¦¬ ì™„ì „ ë¹„ë™ê¸°, ë¬¸ì œ ìƒì„± ë³‘ë ¬ 2ë¬¸ì œì”©, use_sampling={use_sampling})")

            # ë‚œì´ë„ ê°’ ê²€ì¦
            if not isinstance(request.difficulty, DifficultyLevel):
                try:
                    request.difficulty = DifficultyLevel(request.difficulty)
                except ValueError:
                    return {
                        "success": False,
                        "error": f"ì˜ëª»ëœ íŒŒë¼ë¯¸í„°: '{request.difficulty}' is not a valid DifficultyLevel",
                        "valid_difficulty": [level.value for level in DifficultyLevel],
                        "valid_question_types": [qtype.value for qtype in QuestionType]
                    }

            # ë¬¸ì œ ìœ í˜• ê°’ ê²€ì¦
            if not isinstance(request.question_type, QuestionType):
                try:
                    request.question_type = QuestionType(request.question_type)
                except ValueError:
                    return {
                        "success": False,
                        "error": f"ì˜ëª»ëœ íŒŒë¼ë¯¸í„°: '{request.question_type}' is not a valid QuestionType",
                        "valid_difficulty": [level.value for level in DifficultyLevel],
                        "valid_question_types": [qtype.value for qtype in QuestionType]
                    }

            preprocess_start = time.time()
            logger.info(f"[ì „ì²˜ë¦¬] ì‹œì‘ (ë¬¸ì„œë³„ ì™„ì „ ë¹„ë™ê¸°, use_sampling={use_sampling})")

            async def process_single_doc(doc):
                filename = doc.get("filename", "Unknown")
                content = doc.get("content", "")
                if use_sampling:
                    content = self.smart_truncate(content, 2000)
                summary_prompt = self.prompt_manager.get_prompt("summary").format(content=content)
                topic_prompt = self.prompt_manager.get_prompt("topic").format(
                    content=content,
                    difficulty=request.difficulty.value,
                    num_questions=request.num_questions,
                    question_type=request.question_type.value,
                    num_topics=request.num_questions + 3
                )
                keyword_prompt = self.prompt_manager.get_prompt("keyword").format(
                    content=content,
                    difficulty=request.difficulty.value,
                    question_type=request.question_type.value,
                    num_keywords=request.num_questions * 3
                )
                s_task = self.summary_chain.ainvoke({"prompt": summary_prompt})
                t_task = self.topic_chain.ainvoke({"prompt": topic_prompt})
                k_task = self.keyword_chain.ainvoke({"prompt": keyword_prompt})
                summary_resp, topic_resp, keyword_resp = await asyncio.gather(s_task, t_task, k_task)
                return {
                    "summary": summary_resp.content,
                    "topics": topic_resp.content,
                    "keywords": keyword_resp.content
                }

            doc_tasks = [process_single_doc(doc) for doc in documents]
            doc_results = await asyncio.gather(*doc_tasks)

            # ê²°ê³¼ í•©ì¹˜ê¸°
            summary = "\n".join([r["summary"] for r in doc_results])
            topics = []
            for r in doc_results:
                topics.extend([line.strip().lstrip('- â€¢').strip() for line in r["topics"].split('\n') if line.strip().startswith(('-', 'â€¢'))])
            keywords = []
            for r in doc_results:
                keywords.extend([kw.strip() for kw in r["keywords"].split(',') if kw.strip()])
            logger.info(f"[ì „ì²˜ë¦¬] ì™„ë£Œ (ì´ ì†Œìš” ì‹œê°„: {time.time() - preprocess_start:.2f}ì´ˆ)")

            # 2. ë¬¸ì œ ìƒì„±: ë” ë§ì€ ë¬¸ì œë¥¼ ìƒì„±í•˜ì—¬ ë¶€ì¡±í•œ ê²½ìš° ëŒ€ë¹„
            generate_start = time.time()
            logger.info("[ë¬¸ì œ ìƒì„±] ì‹œì‘ (ë” ë§ì€ ë¬¸ì œ ìƒì„±)")

            # ìš”ì²­ ìˆ˜ì˜ 1.5ë°°ë¡œ ìƒì„±í•˜ì—¬ í’ˆì§ˆ ê²€ì‚¬ í›„ í•„í„°ë§ ëŒ€ë¹„
            target_questions = int(request.num_questions * 1.5)
            batch_size = 3  # ë°°ì¹˜ í¬ê¸° ì¦ê°€
            total_batches = (target_questions + batch_size - 1) // batch_size

            async def generate_questions_batch(batch_num):
                question_prompt = self.prompt_manager.get_prompt("question").format(
                    summary=summary,
                    topics="\n".join(f"- {topic}" for topic in topics),
                    keywords="\n".join(f"- {keyword}" for keyword in keywords),
                    num_questions=batch_size,
                    difficulty=request.difficulty.value,
                    question_type=request.question_type.value
                )
                response = await self.question_chain.ainvoke({
                    "system_message": "ë‹¹ì‹ ì€ ì „ë¬¸ êµìœ¡ ì»¨í…ì¸  ê°œë°œìì…ë‹ˆë‹¤.",
                    "prompt": question_prompt
                })
                return self._parse_questions(response.content)

            tasks = [generate_questions_batch(i) for i in range(total_batches)]
            results = await asyncio.gather(*tasks)
            questions = [q for batch in results for q in batch]

            # í’ˆì§ˆ ê²€ì‚¬ í›„ ë¬¸ì œ ìˆ˜ê°€ ë¶€ì¡±í•œ ê²½ìš° ì¶”ê°€ ìƒì„±
            questions = self._basic_quality_check(questions)
            if len(questions) < request.num_questions:
                logger.info(f"ë¬¸ì œ ìˆ˜ ë¶€ì¡± ({len(questions)}/{request.num_questions}), ì¶”ê°€ ìƒì„± ì‹œì‘")

                # ë¶€ì¡±í•œ ìˆ˜ì˜ 2ë°°ë¡œ ì¶”ê°€ ìƒì„±
                additional_needed = (request.num_questions - len(questions)) * 2
                additional_batches = (additional_needed + batch_size - 1) // batch_size

                additional_tasks = [generate_questions_batch(i) for i in range(additional_batches)]
                additional_results = await asyncio.gather(*additional_tasks)
                additional_questions = [q for batch in additional_results for q in batch]
                additional_questions = self._basic_quality_check(additional_questions)

                questions.extend(additional_questions)
                logger.info(f"ì¶”ê°€ ìƒì„± ì™„ë£Œ: ì´ {len(questions)}ê°œ ë¬¸ì œ")

            logger.info(f"[ë¬¸ì œ ìƒì„±] ì™„ë£Œ (ì†Œìš” ì‹œê°„: {time.time() - generate_start:.2f}ì´ˆ)")

            # 3. í›„ì²˜ë¦¬: ID ë¶€ì—¬ ë° ìµœì¢… ì •ë¦¬
            post_start = time.time()
            logger.info("[í›„ì²˜ë¦¬] ì‹œì‘")
            # í’ˆì§ˆ ê²€ì‚¬ëŠ” ì´ë¯¸ ë¬¸ì œ ìƒì„± ë‹¨ê³„ì—ì„œ ì™„ë£Œë¨
            questions = questions[:request.num_questions]  # ìš”ì²­ ìˆ˜ë§Œí¼ë§Œ ë°˜í™˜
            for i, question in enumerate(questions, 1):
                question["id"] = i
                # ì „ì²˜ë¦¬ì—ì„œ ì´ë¯¸ ì„ íƒì§€ ë²ˆí˜¸ì™€ correct_answer_numberê°€ ì²˜ë¦¬ë˜ì—ˆìœ¼ë¯€ë¡œ ì¶”ê°€ ì²˜ë¦¬ ì œê±°
                # ë‹¤ì¤‘ì„ íƒ ë¬¸ì œì˜ ê²½ìš° ì „ì²˜ë¦¬ì—ì„œ ì´ë¯¸ ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ì²˜ë¦¬ë¨
            logger.info(f"[í›„ì²˜ë¦¬] ì™„ë£Œ (ì†Œìš” ì‹œê°„: {time.time() - post_start:.2f}ì´ˆ)")

            total_end = time.time()
            logger.info(f"[ì‹¤í–‰ì‹œê°„] ì „ì²´ ë¬¸ì œ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì†Œìš” ì‹œê°„: {total_end - total_start:.2f}ì´ˆ")
            logger.info("ğŸ‰ SUCCESS ë¬¸ì œ ìƒì„± ì™„ë£Œ")

            return {
                "success": True,
                "request": {
                    "file_ids": request.file_ids,
                    "num_questions": request.num_questions,
                    "difficulty": request.difficulty.value,
                    "question_type": request.question_type.value
                },
                "process_info": {
                    "summary": summary,
                    "core_topics": topics,
                    "keywords": keywords
                },
                "questions": questions,
                "meta": {
                    "generated_count": len(questions),
                    "final_step": "generate_quiz"
                }
            }
        except Exception as e:
            logger.error(f"ERROR ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "request": {
                    "file_ids": request.file_ids,
                    "num_questions": request.num_questions,
                    "difficulty": request.difficulty.value,
                    "question_type": request.question_type.value
                }
            }