"""
ğŸ¤– Quiz Generation AI Agent using LangGraph
"""
import logging
import os
from typing import Dict, List, Any, Optional, TypedDict
from dataclasses import dataclass
from enum import Enum
import json
import time

# tokenizers ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
os.environ["TOKENIZERS_PARALLELISM"] = "false"

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langchain.prompts import ChatPromptTemplate

# ğŸ”¥ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ì ì„í¬íŠ¸
from .prompt import QuizPromptManager
from .prompt.quiz_prompt_manager import DifficultyLevel, QuestionType

logger = logging.getLogger(__name__)


@dataclass
class QuizRequest:
    """ë¬¸ì œ ìƒì„± ìš”ì²­"""
    file_ids: List[str]                 # ëŒ€ìƒ íŒŒì¼ IDë“¤
    num_questions: int = 5              # ìƒì„±í•  ë¬¸ì œ ìˆ˜
    difficulty: DifficultyLevel = DifficultyLevel.MEDIUM
    question_type: QuestionType = QuestionType.MULTIPLE_CHOICE
    custom_topic: Optional[str] = None  # íŠ¹ì • ì£¼ì œ ì§€ì •
    additional_instructions: Optional[List[str]] = None  # ì¶”ê°€ ì§€ì‹œì‚¬í•­


class QuizState(TypedDict):
    """LangGraph ìƒíƒœ ê´€ë¦¬"""
    # ì…ë ¥
    request: QuizRequest
    documents: List[Dict[str, Any]]

    # ì›Œí¬í”Œë¡œìš° ìƒíƒœ
    summary: str
    core_topics: List[str]
    keywords: List[str]
    generated_questions: List[Dict[str, Any]]

    # ë©”íƒ€ë°ì´í„°
    current_step: str
    errors: List[str]
    domain_context: Dict[str, Any]


class QuizGeneratorAgent:
    """ë¬¸ì œ ìƒì„± AI ì—ì´ì „íŠ¸"""

    def __init__(self, openai_api_key: Optional[str] = None):
        """
        ì´ˆê¸°í™”
        Args:
            openai_api_key: OpenAI API í‚¤ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ ë¡œë“œ ê°€ëŠ¥)
        """
        self.openai_api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        if not self.openai_api_key:
            raise ValueError("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ ì§ì ‘ ì „ë‹¬í•˜ì„¸ìš”.")

        # LLM ëª¨ë¸ ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",  # ë¹„ìš© íš¨ìœ¨ì ì¸ ëª¨ë¸
            temperature=0.7,      # ì°½ì˜ì„±ê³¼ ì¼ê´€ì„±ì˜ ê· í˜•
            api_key=self.openai_api_key
        )

        # LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±
        self.workflow = self._create_workflow()

        # ğŸ¯ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ì ì´ˆê¸°í™”
        self.prompt_manager = QuizPromptManager()

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì´ˆê¸°í™”
        self.summary_template = ChatPromptTemplate.from_messages([
            ("system", "ë‹¹ì‹ ì€ ì „ë¬¸ êµìœ¡ ì»¨í…ì¸  ë¶„ì„ê°€ì…ë‹ˆë‹¤."),
            ("human", "{prompt}")
        ])

        self.topic_template = ChatPromptTemplate.from_messages([
            ("system", "ë‹¹ì‹ ì€ ì „ë¬¸ êµìœ¡ê³¼ì • ì„¤ê³„ìì…ë‹ˆë‹¤."),
            ("human", "{prompt}")
        ])

        self.keyword_template = ChatPromptTemplate.from_messages([
            ("system", "ë‹¹ì‹ ì€ ì „ë¬¸ ì‹œí—˜ ì¶œì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
            ("human", "{prompt}")
        ])

        self.question_template = ChatPromptTemplate.from_messages([
            ("system", "{system_message}"),
            ("human", "{prompt}")
        ])

        self.validation_template = ChatPromptTemplate.from_messages([
            ("system", "ë‹¹ì‹ ì€ ì „ë¬¸ êµìœ¡ ì»¨í…ì¸  í’ˆì§ˆ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
            ("human", "{prompt}")
        ])

        # ì²´ì¸ ì´ˆê¸°í™”
        self.summary_chain = self.summary_template | self.llm
        self.topic_chain = self.topic_template | self.llm
        self.keyword_chain = self.keyword_template | self.llm
        self.question_chain = self.question_template | self.llm
        self.validation_chain = self.validation_template | self.llm

    def _create_workflow(self) -> StateGraph:
        """LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        workflow = StateGraph(QuizState)

        # ë³‘ë ¬ ì²˜ë¦¬ ë…¸ë“œ ì¶”ê°€
        workflow.add_node("parallel_processor", self._parallel_process)
        workflow.add_node("question_generator", self._generate_questions)

        # ì›Œí¬í”Œë¡œìš° ìˆœì„œ ì •ì˜
        workflow.set_entry_point("parallel_processor")
        workflow.add_edge("parallel_processor", "question_generator")
        workflow.add_edge("question_generator", END)

        return workflow.compile()

    async def _parallel_process(self, state: QuizState) -> QuizState:
        """ğŸ“„ ë³‘ë ¬ ì²˜ë¦¬: ë¬¸ì„œ ìš”ì•½, í•µì‹¬ ì£¼ì œ ì¶”ì¶œ, í‚¤ì›Œë“œ ì¶”ì¶œ"""
        try:
            parallel_start = time.time()
            logger.info("ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘")

            # ë¬¸ì„œ ë‚´ìš© ê²°í•© ë° ì „ì²˜ë¦¬
            combined_content = ""
            domain_info = {}
            total_sentences = 0
            total_paragraphs = 0

            for doc in state["documents"]:
                filename = doc.get("filename", "Unknown")
                content = doc.get("content", "")

                # ë¬¸ì¥ê³¼ ë‹¨ë½ ìˆ˜ ê³„ì‚°
                sentences = [s.strip() for s in content.split('.') if s.strip()]
                paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
                total_sentences += len(sentences)
                total_paragraphs += len(paragraphs)

                combined_content += f"\n\n=== {filename} ===\n{content}"
                domain_info[filename] = {
                    "language": doc.get("language", "unknown"),
                    "file_size": doc.get("file_size", 0),
                    "chunk_count": doc.get("total_chunks", 0),
                    "sentence_count": len(sentences),
                    "paragraph_count": len(paragraphs)
                }

            # ë¬¸ì œ ìˆ˜ ì¬ê³„ì‚°
            base_questions = max(3, total_sentences // 4)  # 4ë¬¸ì¥ë‹¹ 1ë¬¸ì œ
            complexity_factor = min(1.5, 1 + (total_paragraphs / total_sentences))
            concept_factor = min(0.5, len(domain_info) * 0.1)

            recommended_questions = int(base_questions * complexity_factor * (1 + concept_factor))
            recommended_questions = min(max(5, recommended_questions), 20)  # 5-20ê°œ ì‚¬ì´ë¡œ ì œí•œ

            # ë¬¸ì œ ìˆ˜ ì—…ë°ì´íŠ¸
            state["request"].num_questions = recommended_questions

            # ë³‘ë ¬ ì²˜ë¦¬ íƒœìŠ¤í¬ ì •ì˜
            async def summarize_documents():
                summary_prompt = self.prompt_manager.get_prompt("summary").format(
                    content=combined_content
                )
                return await self.summary_chain.ainvoke({"prompt": summary_prompt})

            async def extract_topics():
                topic_prompt = self.prompt_manager.get_prompt("topic").format(
                    content=combined_content,
                    difficulty=state["request"].difficulty.value,
                    num_questions=recommended_questions,
                    question_type=state["request"].question_type.value,
                    num_topics=recommended_questions + 3
                )
                return await self.topic_chain.ainvoke({"prompt": topic_prompt})

            async def extract_keywords():
                keyword_prompt = self.prompt_manager.get_prompt("keyword").format(
                    content=combined_content,
                    difficulty=state["request"].difficulty.value,
                    question_type=state["request"].question_type.value,
                    num_keywords=recommended_questions * 3
                )
                return await self.keyword_chain.ainvoke({"prompt": keyword_prompt})

            # ë³‘ë ¬ ì‹¤í–‰
            import asyncio
            topics_response, summary_response, keywords_response = await asyncio.gather(
                extract_topics(), summarize_documents(), extract_keywords()
            )
            logger.info(f"[ì „ì²˜ë¦¬] ë³‘ë ¬ ì „ì²´ ì†Œìš” ì‹œê°„: {time.time() - parallel_start:.2f}ì´ˆ")
            summary = summary_response.content
            topics = [line.strip().lstrip('- â€¢').strip() for line in topics_response.content.split('\n') if line.strip().startswith(('-', 'â€¢'))]
            keywords = [kw.strip() for kw in keywords_response.content.split(',') if kw.strip()]
            logger.info(f"[ì „ì²˜ë¦¬] ì™„ë£Œ (ì´ ì†Œìš” ì‹œê°„: {time.time() - parallel_start:.2f}ì´ˆ)")

            # ìƒíƒœ ì—…ë°ì´íŠ¸
            state["summary"] = summary
            state["core_topics"] = topics
            state["keywords"] = keywords
            state["domain_context"] = {
                **domain_info,
                "total_sentences": total_sentences,
                "total_paragraphs": total_paragraphs,
                "recommended_questions": recommended_questions
            }
            state["current_step"] = "parallel_processor"

            logger.info(f"SUCCESS ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ: {recommended_questions}ê°œ ë¬¸ì œ ì¶”ì²œ")
            return state

        except Exception as e:
            logger.error(f"ERROR ë³‘ë ¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            state["errors"].append(f"ë³‘ë ¬ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return state

    async def _generate_questions(self, state: QuizState) -> QuizState:
        """â“ 4ë‹¨ê³„: ê· í˜• ì¡íŒ ë¬¸ì œ ìƒì„±"""
        try:
            generate_start = time.time()
            logger.info("STEP4 ê· í˜• ì¡íŒ ë¬¸ì œ ìƒì„± ì‹œì‘")

            request = state["request"]
            summary = state["summary"]
            topics = state["core_topics"]
            keywords = state["keywords"]

            # ì¶”ê°€ ì§€ì‹œì‚¬í•­ì´ ìˆëŠ” ê²½ìš° í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
            additional_guide = ""
            if request.additional_instructions:
                additional_guide = "\n\nğŸ“ **ì¶”ê°€ ì§€ì‹œì‚¬í•­**:\n" + "\n".join(f"- {instruction}" for instruction in request.additional_instructions)

            # ğŸ¯ 1ë‹¨ê³„: PDF ê¸°ë°˜ ë¬¸ì œ ìƒì„±
            pdf_prompt = self.prompt_manager.get_prompt("question").format(
                summary=summary,
                topics="\n".join(f"- {topic}" for topic in topics),
                keywords="\n".join(f"- {keyword}" for keyword in keywords),
                num_questions=request.num_questions * 4,  # ìš”ì²­ ìˆ˜ì˜ 4ë°°ë¡œ ìƒì„±
                difficulty=request.difficulty.value,
                question_type=request.question_type.value
            )

            # PDF ê¸°ë°˜ ë¬¸ì œ ìƒì„±ê³¼ AI ê¸°ë°˜ ë¬¸ì œ ìƒì„±ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
            async def generate_pdf_questions():
                response = await self.question_chain.ainvoke({
                    "system_message": "ë‹¹ì‹ ì€ ì „ë¬¸ êµìœ¡ ì»¨í…ì¸  ê°œë°œìì…ë‹ˆë‹¤.",
                    "prompt": pdf_prompt
                })
                return self._parse_questions(response.content)

            async def generate_ai_questions():
                # AI ê¸°ë°˜ ë¬¸ì œ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
                ai_prompt = self.prompt_manager.get_prompt("question").format(
                    summary=summary,
                    topics="\n".join(f"- {topic}" for topic in topics),
                    keywords="\n".join(f"- {keyword}" for keyword in keywords),
                    num_questions=request.num_questions * 3,  # ìš”ì²­ ìˆ˜ì˜ 3ë°°ë¡œ ìƒì„±
                    difficulty=request.difficulty.value,
                    question_type=request.question_type.value
                )
                response = await self.question_chain.ainvoke({
                    "system_message": "ë‹¹ì‹ ì€ ì „ë¬¸ êµìœ¡ ì»¨í…ì¸  ê°œë°œìì…ë‹ˆë‹¤.",
                    "prompt": ai_prompt
                })
                return self._parse_questions(response.content)

            # ë³‘ë ¬ ì‹¤í–‰
            import asyncio
            pdf_questions, ai_questions = await asyncio.gather(
                generate_pdf_questions(),
                generate_ai_questions()
            )

            # ğŸ“Š ìµœì¢… ë¬¸ì œ ëª©ë¡ ìƒì„±
            final_questions = pdf_questions + ai_questions

            # ğŸ”„ ë¬¸ì œ ìˆœì„œ ì„ê¸°
            import random
            random.shuffle(final_questions)

            # ê¸°ë³¸ í’ˆì§ˆ ê²€ì‚¬
            final_questions = self._basic_quality_check(final_questions)

            # ë¬¸ì œ ìˆ˜ê°€ ë¶€ì¡±í•œ ê²½ìš° ì¬ì‹œë„
            retry_count = 0
            while len(final_questions) < request.num_questions and retry_count < 3:  # ìµœëŒ€ 3ë²ˆê¹Œì§€ ì¬ì‹œë„
                logger.info(f"ë¬¸ì œ ìˆ˜ ë¶€ì¡± ({len(final_questions)}/{request.num_questions}), ì¶”ê°€ ìƒì„± ì‹œë„ {retry_count + 1}")

                # ì¶”ê°€ ë¬¸ì œ ìƒì„± (ë¶€ì¡±í•œ ìˆ˜ì˜ 3ë°°ë¡œ ìƒì„±)
                additional_prompt = self.prompt_manager.get_prompt("question").format(
                    summary=summary,
                    topics="\n".join(f"- {topic}" for topic in topics),
                    keywords="\n".join(f"- {keyword}" for keyword in keywords),
                    num_questions=(request.num_questions - len(final_questions)) * 3,
                    difficulty=request.difficulty.value,
                    question_type=request.question_type.value
                )

                response = await self.question_chain.ainvoke({
                    "system_message": "ë‹¹ì‹ ì€ ì „ë¬¸ êµìœ¡ ì»¨í…ì¸  ê°œë°œìì…ë‹ˆë‹¤.",
                    "prompt": additional_prompt
                })

                additional_questions = self._parse_questions(response.content)
                additional_questions = self._basic_quality_check(additional_questions)

                final_questions.extend(additional_questions)
                retry_count += 1

            # ìµœì¢… ì¤‘ë³µ ì œê±° ë° í’ˆì§ˆ ê²€ì‚¬ í•œ ë²ˆ ë”
            final_questions = self._basic_quality_check(final_questions)

            # ë¬¸ì œ ìˆ˜ ì¡°ì • (ìµœì¢…ì ìœ¼ë¡œ ë°˜ë“œì‹œ ìš”ì²­ ìˆ˜ë§Œí¼ë§Œ ë°˜í™˜)
            final_questions = final_questions[:request.num_questions]

            # ID ìˆœì°¨ì ìœ¼ë¡œ ë¶€ì—¬
            for i, question in enumerate(final_questions, 1):
                question["id"] = i

                # ë‹¤ì¤‘ì„ íƒ ë¬¸ì œì˜ ê²½ìš° ë³´ê¸° ë²ˆí˜¸ ì¶”ê°€
                if question.get("type") == "multiple_choice" and isinstance(question.get("options"), list):
                    numbered_options = []
                    for idx, opt in enumerate(question["options"], 1):
                        numbered_options.append(f"{idx}. {opt}")
                    question["options"] = numbered_options

                    # ì •ë‹µë„ ë²ˆí˜¸ë¡œ ë³€í™˜
                    if "correct_answer" in question:
                        try:
                            answer_idx = [opt.replace(f"{idx}. ", "") for idx, opt in enumerate(numbered_options, 1)].index(question["correct_answer"]) + 1
                            question["correct_answer_number"] = answer_idx
                        except Exception:
                            question["correct_answer_number"] = None

            state["generated_questions"] = final_questions
            state["current_step"] = "question_generator"

            # ğŸ“Š ë¶„í¬ í™•ì¸ ë¡œê¹…
            basic_count = sum(1 for q in final_questions if q.get("problem_level") == "basic")
            concept_count = sum(1 for q in final_questions if q.get("problem_level") == "concept")
            app_count = sum(1 for q in final_questions if q.get("problem_level") == "application")
            pdf_count = sum(1 for q in final_questions if q.get("source") != "ai_generated")
            ai_count = sum(1 for q in final_questions if q.get("source") == "ai_generated")

            logger.info(f"SUCCESS ë¬¸ì œ ìƒì„± ì™„ë£Œ: ì´ {len(final_questions)}ê°œ")
            logger.info(f"- PDF ê¸°ë°˜: {pdf_count}ê°œ")
            logger.info(f"- AI ê¸°ë°˜: {ai_count}ê°œ")
            logger.info(f"- ê¸°ë³¸ ê°œë…: {basic_count}ê°œ")
            logger.info(f"- ê°œë… ì—°ê³„: {concept_count}ê°œ")
            logger.info(f"- ì‘ìš© ë¬¸ì œ: {app_count}ê°œ")
            logger.info(f"[ì‹¤í–‰ì‹œê°„] ë¬¸ì œ ìƒì„± ì†Œìš” ì‹œê°„: {time.time() - generate_start:.2f}ì´ˆ")

            return state

        except Exception as e:
            logger.error(f"ERROR ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")
            state["errors"].append(f"ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return state

    def _basic_quality_check(self, questions: List[Dict]) -> List[Dict]:
        """ê¸°ë³¸ì ì¸ í’ˆì§ˆ ê²€ì‚¬ ìˆ˜í–‰"""
        valid_questions = []
        seen_questions = set()

        for q in questions:
            try:
                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                if not all(k in q for k in ["question", "options", "correct_answer", "explanation"]):
                    continue

                # ì¤‘ë³µ ë¬¸ì œ ì œê±° (ìœ ì‚¬ë„ ê¸°ë°˜, ê¸°ì¤€ ì™„í™”)
                question_text = q["question"].lower().strip()
                if any(self._is_similar(question_text, seen, threshold=0.9) for seen in seen_questions):  # ìœ ì‚¬ë„ ê¸°ì¤€ ìƒí–¥
                    continue
                seen_questions.add(question_text)

                # ì„ íƒì§€ ê²€ì¦ (ìµœì†Œ 2ê°œ ì´ìƒ)
                if len(q["options"]) < 2:
                    continue

                # ì •ë‹µì´ ì„ íƒì§€ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                if q["correct_answer"] not in q["options"]:
                    continue

                # ë¬¸ì œ ìˆ˜ì¤€ ì„¤ì •
                if "problem_level" not in q:
                    q["problem_level"] = "basic"

                valid_questions.append(q)
            except Exception as e:
                logger.warning(f"ë¬¸ì œ í’ˆì§ˆ ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue

        return valid_questions

    def _is_similar(self, text1: str, text2: str, threshold: float = 0.9) -> bool:
        """ë‘ í…ìŠ¤íŠ¸ì˜ ìœ ì‚¬ë„ ê²€ì‚¬ (ê¸°ì¤€ ìƒí–¥)"""
        from difflib import SequenceMatcher
        return SequenceMatcher(None, text1, text2).ratio() > threshold

    def _parse_questions(self, content: str) -> List[Dict]:
        """JSON ì‘ë‹µ íŒŒì‹±"""
        try:
            if "```json" in content:
                json_start = content.find("```json") + 7
                json_end = content.find("```", json_start)
                json_content = content[json_start:json_end].strip()
            elif "```" in content:
                json_start = content.find("```") + 3
                json_end = content.find("```", json_start)
                json_content = content[json_start:json_end].strip()
            else:
                json_content = content.strip()

            questions_data = json.loads(json_content)
            return questions_data.get("questions", [])

        except json.JSONDecodeError as e:
            logger.error(f"ERROR JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.error(f"LLM ì‘ë‹µ ë‚´ìš©: {content[:500]}...")
            return []

    def smart_truncate(self, text, max_length=2000):
        """ì•/ì¤‘ê°„/ë ìƒ˜í”Œë§ ë°©ì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ìë¦„"""
        if len(text) <= max_length:
            return text
        part = max_length // 3
        return text[:part] + text[len(text)//2:len(text)//2+part] + text[-part:]

    async def generate_quiz(self, request: QuizRequest, documents: List[Dict[str, Any]], use_combined_prompt: bool = False, use_sampling: bool = False) -> Dict[str, Any]:
        """
        ë¬¸ì œ ìƒì„± ë©”ì¸ ë©”ì„œë“œ (ë¬¸ì„œë³„ ì „ì²˜ë¦¬ê¹Œì§€ ì™„ì „ ë¹„ë™ê¸° + ë¬¸ì œ ìƒì„± 2ë¬¸ì œì”© ë³‘ë ¬)
        use_combined_prompt: ë¬´ì‹œ(í•­ìƒ ë¶„ë¦¬ ë°©ì‹)
        use_sampling: Trueë©´ ìƒ˜í”Œë§(ì•/ì¤‘ê°„/ë), Falseë©´ ì „ì²´ ê²°í•©
        """
        import time
        try:
            total_start = time.time()
            logger.info(f"ğŸš€ ë¬¸ì œ ìƒì„± AI ì—ì´ì „íŠ¸ ì‹œì‘ (ë¬¸ì„œë³„ ì „ì²˜ë¦¬ ì™„ì „ ë¹„ë™ê¸°, ë¬¸ì œ ìƒì„± ë³‘ë ¬ 2ë¬¸ì œì”©, use_sampling={use_sampling})")

            # ë‚œì´ë„ ê°’ ê²€ì¦
            if not isinstance(request.difficulty, DifficultyLevel):
                try:
                    request.difficulty = DifficultyLevel(request.difficulty)
                except ValueError:
                    return {
                        "success": False,
                        "error": f"ì˜ëª»ëœ íŒŒë¼ë¯¸í„°: '{request.difficulty}' is not a valid DifficultyLevel",
                        "valid_difficulty": [level.value for level in DifficultyLevel],
                        "valid_question_types": [qtype.value for qtype in QuestionType]
                    }

            # ë¬¸ì œ ìœ í˜• ê°’ ê²€ì¦
            if not isinstance(request.question_type, QuestionType):
                try:
                    request.question_type = QuestionType(request.question_type)
                except ValueError:
                    return {
                        "success": False,
                        "error": f"ì˜ëª»ëœ íŒŒë¼ë¯¸í„°: '{request.question_type}' is not a valid QuestionType",
                        "valid_difficulty": [level.value for level in DifficultyLevel],
                        "valid_question_types": [qtype.value for qtype in QuestionType]
                    }

            preprocess_start = time.time()
            logger.info(f"[ì „ì²˜ë¦¬] ì‹œì‘ (ë¬¸ì„œë³„ ì™„ì „ ë¹„ë™ê¸°, use_sampling={use_sampling})")

            import asyncio
            async def process_single_doc(doc):
                filename = doc.get("filename", "Unknown")
                content = doc.get("content", "")
                if use_sampling:
                    content = self.smart_truncate(content, 2000)
                summary_prompt = self.prompt_manager.get_prompt("summary").format(content=content)
                topic_prompt = self.prompt_manager.get_prompt("topic").format(
                    content=content,
                    difficulty=request.difficulty.value,
                    num_questions=request.num_questions,
                    question_type=request.question_type.value,
                    num_topics=request.num_questions + 3
                )
                keyword_prompt = self.prompt_manager.get_prompt("keyword").format(
                    content=content,
                    difficulty=request.difficulty.value,
                    question_type=request.question_type.value,
                    num_keywords=request.num_questions * 3
                )
                s_task = self.summary_chain.ainvoke({"prompt": summary_prompt})
                t_task = self.topic_chain.ainvoke({"prompt": topic_prompt})
                k_task = self.keyword_chain.ainvoke({"prompt": keyword_prompt})
                summary_resp, topic_resp, keyword_resp = await asyncio.gather(s_task, t_task, k_task)
                return {
                    "summary": summary_resp.content,
                    "topics": topic_resp.content,
                    "keywords": keyword_resp.content
                }

            doc_tasks = [process_single_doc(doc) for doc in documents]
            doc_results = await asyncio.gather(*doc_tasks)

            # ê²°ê³¼ í•©ì¹˜ê¸°
            summary = "\n".join([r["summary"] for r in doc_results])
            topics = []
            for r in doc_results:
                topics.extend([line.strip().lstrip('- â€¢').strip() for line in r["topics"].split('\n') if line.strip().startswith(('-', 'â€¢'))])
            keywords = []
            for r in doc_results:
                keywords.extend([kw.strip() for kw in r["keywords"].split(',') if kw.strip()])
            logger.info(f"[ì „ì²˜ë¦¬] ì™„ë£Œ (ì´ ì†Œìš” ì‹œê°„: {time.time() - preprocess_start:.2f}ì´ˆ)")

            # 2. ë¬¸ì œ ìƒì„±: 2ë¬¸ì œì”© 5ë²ˆ ë³‘ë ¬
            generate_start = time.time()
            logger.info("[ë¬¸ì œ ìƒì„±] ì‹œì‘ (2ë¬¸ì œì”© 5íšŒ ë³‘ë ¬)")
            batch_size = 2
            total_batches = (request.num_questions + batch_size - 1) // batch_size
            async def generate_questions_batch(batch_num):
                question_prompt = self.prompt_manager.get_prompt("question").format(
                    summary=summary,
                    topics="\n".join(f"- {topic}" for topic in topics),
                    keywords="\n".join(f"- {keyword}" for keyword in keywords),
                    num_questions=batch_size,
                    difficulty=request.difficulty.value,
                    question_type=request.question_type.value
                )
                response = await self.question_chain.ainvoke({
                    "system_message": "ë‹¹ì‹ ì€ ì „ë¬¸ êµìœ¡ ì»¨í…ì¸  ê°œë°œìì…ë‹ˆë‹¤.",
                    "prompt": question_prompt
                })
                return self._parse_questions(response.content)
            tasks = [generate_questions_batch(i) for i in range(total_batches)]
            results = await asyncio.gather(*tasks)
            questions = [q for batch in results for q in batch]
            logger.info(f"[ë¬¸ì œ ìƒì„±] ì™„ë£Œ (ì†Œìš” ì‹œê°„: {time.time() - generate_start:.2f}ì´ˆ)")

            # 3. í›„ì²˜ë¦¬: ì¤‘ë³µ ì œê±°, í’ˆì§ˆ ê²€ì‚¬, ìŠ¬ë¼ì´ì‹±, ë³´ê¸° ë²ˆí˜¸ ë¶€ì—¬
            post_start = time.time()
            logger.info("[í›„ì²˜ë¦¬] ì‹œì‘")
            questions = self._basic_quality_check(questions)
            questions = questions[:request.num_questions]
            for i, question in enumerate(questions, 1):
                question["id"] = i
                if question.get("type") == "multiple_choice" and isinstance(question.get("options"), list):
                    numbered_options = []
                    for idx, opt in enumerate(question["options"], 1):
                        numbered_options.append(f"{idx}. {opt}")
                    question["options"] = numbered_options
                    if "correct_answer" in question:
                        try:
                            answer_idx = [opt.replace(f"{idx}. ", "") for idx, opt in enumerate(numbered_options, 1)].index(question["correct_answer"]) + 1
                            question["correct_answer_number"] = answer_idx
                        except Exception:
                            question["correct_answer_number"] = None
            logger.info(f"[í›„ì²˜ë¦¬] ì™„ë£Œ (ì†Œìš” ì‹œê°„: {time.time() - post_start:.2f}ì´ˆ)")

            total_end = time.time()
            logger.info(f"[ì‹¤í–‰ì‹œê°„] ì „ì²´ ë¬¸ì œ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì†Œìš” ì‹œê°„: {total_end - total_start:.2f}ì´ˆ")
            logger.info("ğŸ‰ SUCCESS ë¬¸ì œ ìƒì„± ì™„ë£Œ")

            return {
                "success": True,
                "request": {
                    "file_ids": request.file_ids,
                    "num_questions": request.num_questions,
                    "difficulty": request.difficulty.value,
                    "question_type": request.question_type.value
                },
                "process_info": {
                    "summary": summary,
                    "core_topics": topics,
                    "keywords": keywords
                },
                "questions": questions,
                "meta": {
                    "generated_count": len(questions),
                    "final_step": "generate_quiz"
                }
            }
        except Exception as e:
            logger.error(f"ERROR ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "request": {
                    "file_ids": request.file_ids,
                    "num_questions": request.num_questions,
                    "difficulty": request.difficulty.value,
                    "question_type": request.question_type.value
                }
            }