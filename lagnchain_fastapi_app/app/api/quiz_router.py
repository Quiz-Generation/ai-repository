"""
í€´ì¦ˆ ìƒì„± API ë¼ìš°í„°
PDF ë¬¸ì„œ ê¸°ë°˜ RAG í€´ì¦ˆ ìƒì„± ì‹œìŠ¤í…œ

ì£¼ìš” ì—”ë“œí¬ì¸íŠ¸:
- POST /quiz/generate: í€´ì¦ˆ ìƒì„± (ë©”ì¸ ê¸°ëŠ¥)
- GET /quiz/topics/{document_id}: ë¬¸ì„œ í† í”½ ì¶”ì¶œ
- POST /quiz/switch-llm: LLM ëª¨ë¸ êµì²´
- GET /quiz/health: ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
"""

from fastapi import APIRouter, HTTPException, Body, Path, Query
from fastapi.responses import JSONResponse
import logging
import time
from typing import List, Dict, Any, Optional

# í€´ì¦ˆ ì„œë¹„ìŠ¤ ë° ìŠ¤í‚¤ë§ˆ import
from ..services.quiz_service import get_default_quiz_service
from ..services.llm_factory import LLMFactory, LLMProvider, LLMConfig
from ..schemas.quiz_schema import (
    QuizRequest,  Difficulty, QuestionType,
    QuizRequestAPI, QuestionAPI
)

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/quiz", tags=["Quiz Generation"])

# ì „ì—­ í€´ì¦ˆ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
quiz_service = get_default_quiz_service()


@router.get("/health")
async def health_check() -> JSONResponse:
    """ğŸ” í€´ì¦ˆ ìƒì„± ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    try:
        return JSONResponse(
            status_code=200,
            content={
                "status": "healthy",
                "service": "PDF RAG Quiz Generation Service",
                "llm_model": quiz_service.llm_service.model_name,
                "llm_provider": quiz_service.llm_service.provider.value,
                "vector_db": quiz_service.vector_service.db_type,
                "supported_features": [
                    "PDF ê¸°ë°˜ í€´ì¦ˆ ìƒì„±",
                    "RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰",
                    "ë™ì  í† í”½ ì¶”ì¶œ",
                    "ë‹¤ì–‘í•œ ë¬¸ì œ ìœ í˜•",
                    "ë‚œì´ë„ë³„ ë¬¸ì œ ìƒì„±",
                    "LLM ëª¨ë¸ êµì²´",
                    "ë¬¸ì œ í’ˆì§ˆ ê²€ì¦"
                ],
                "available_difficulties": ["easy", "medium", "hard"],
                "available_question_types": [
                    "multiple_choice", "short_answer", "fill_blank", "true_false"
                ],
                "supported_llm_providers": LLMFactory.get_available_providers(),
                "endpoints": [
                    "POST /quiz/generate",
                    "GET /quiz/topics/{document_id}",
                    "POST /quiz/switch-llm",
                    "GET /quiz/health"
                ]
            }
        )
    except Exception as e:
        return JSONResponse(
            status_code=503,
            content={
                "status": "unhealthy",
                "error": str(e)
            }
        )


@router.post("/generate")
async def generate_quiz(request: QuizRequestAPI) -> JSONResponse:
    """ğŸ§  PDF ë¬¸ì„œ ê¸°ë°˜ í€´ì¦ˆ ìë™ ìƒì„± (ë©”ì¸ ê¸°ëŠ¥)

    **ğŸ¤– AIê°€ PDFë¥¼ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ ìµœì ì˜ í€´ì¦ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤**

    **í•µì‹¬ íŠ¹ì§•:**
    - âœ¨ **í† í”½ ìë™ ì¶”ì¶œ**: PDF ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ ì£¼ì œë“¤ì„ ìë™ ì¶”ì¶œ
    - ğŸ¯ **RAG ìµœì í™”**: ê´€ë ¨ì„± ë†’ì€ ì»¨í…ìŠ¤íŠ¸ë§Œ ì„ ë³„í•˜ì—¬ ê³ í’ˆì§ˆ ë¬¸ì œ ìƒì„±
    - ğŸ”„ **ì§€ëŠ¥í˜• ë‚œì´ë„ ì¡°ì ˆ**: ìš”ì²­í•œ ë‚œì´ë„ì— ë§ëŠ” ë¬¸ì œ ìœ í˜•ê³¼ ë³µì¡ë„ ìë™ ì„ íƒ
    - ğŸ“Š **í’ˆì§ˆ ë³´ì¥**: AIê°€ ìƒì„±í•œ ë¬¸ì œë¥¼ ìë™ìœ¼ë¡œ ê²€ì¦

    **ì²˜ë¦¬ ê³¼ì •:**
    1. ğŸ“„ **ë¬¸ì„œ í™•ì¸**: ì—…ë¡œë“œëœ PDF ë¬¸ì„œ ì¡´ì¬ ë° ìƒíƒœ í™•ì¸
    2. ğŸ¤– **í† í”½ ìë™ ì¶”ì¶œ**: AIê°€ PDF ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ ì£¼ì œ ì¶”ì¶œ
    3. ğŸ” **RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰**: ì¶”ì¶œëœ í† í”½ ê¸°ë°˜ìœ¼ë¡œ ìµœì  ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
    4. âš¡ **LLM í€´ì¦ˆ ìƒì„±**: ì»¨í…ìŠ¤íŠ¸ì™€ í† í”½ì„ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì œ ìƒì„±
    5. âœ… **í’ˆì§ˆ ê²€ì¦**: ìƒì„±ëœ ë¬¸ì œì˜ í’ˆì§ˆ ìë™ ê²€ì¦ ë° ìµœì í™”

    **ğŸ“ ìš”ì²­ ì˜ˆì‹œ (ê°„ë‹¨):**
    ```json
    {
        "document_id": "f7dbd017-426e-4919-8a88-feda68949615",
        "num_questions": 5,
        "difficulty": "medium"
    }
    ```
    â†’ AIê°€ ìë™ìœ¼ë¡œ í† í”½ì„ ì¶”ì¶œí•˜ê³  ì ì ˆí•œ ë¬¸ì œ ìœ í˜•ì„ ì„ íƒí•©ë‹ˆë‹¤

    **ğŸ“ ìš”ì²­ ì˜ˆì‹œ (ì»¤ìŠ¤í…€):**
    ```json
    {
        "document_id": "f7dbd017-426e-4919-8a88-feda68949615",
        "num_questions": 8,
        "difficulty": "hard",
        "question_types": ["multiple_choice", "short_answer"],
        "topics": ["ì•Œê³ ë¦¬ì¦˜", "ë³µì¡ë„"]
    }
    ```
    â†’ ìë™ ì¶”ì¶œëœ í† í”½ + íŒíŠ¸ í† í”½ì„ ì¡°í•©í•˜ì—¬ ë” ì •í™•í•œ ë¬¸ì œ ìƒì„±

    **ğŸ’¡ ì‚¬ìš© íŒ:**
    - `topics`ëŠ” ì„ íƒì‚¬í•­ì…ë‹ˆë‹¤. AIê°€ ìë™ìœ¼ë¡œ ìµœì ì˜ í† í”½ì„ ì°¾ì•„ì¤ë‹ˆë‹¤
    - íŠ¹ì • ì£¼ì œì— ì§‘ì¤‘í•˜ê³  ì‹¶ë‹¤ë©´ `topics`ì— íŒíŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”
    - ë‚œì´ë„ì— ë”°ë¼ ë¬¸ì œ ìœ í˜•ì´ ìë™ìœ¼ë¡œ ìµœì í™”ë©ë‹ˆë‹¤
    """

    generation_start = time.time()

    logger.info(f"í€´ì¦ˆ ìƒì„± API ìš”ì²­: {request.document_id} ({request.num_questions}ë¬¸ì œ)")

    try:
        # API ìš”ì²­ì„ ë‚´ë¶€ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜
        internal_request = QuizRequest(
            document_id=request.document_id,
            num_questions=request.num_questions,
            difficulty=Difficulty(request.difficulty),
            question_types=[QuestionType(qt) for qt in request.question_types] if request.question_types else None,
            topics=request.topics,
            language=request.language
        )

        # í€´ì¦ˆ ìƒì„±
        response = quiz_service.generate_quiz(internal_request)

        if not response.success:
            raise HTTPException(status_code=400, detail=f"í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: {response.error}")

        # API ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        api_questions = []
        for question in response.questions:
            api_question = QuestionAPI(
                question=question.question,
                question_type=question.question_type.value,
                correct_answer=question.correct_answer,
                options=question.options,
                explanation=question.explanation,
                difficulty=question.difficulty.value,
                topic=question.topic
            )
            api_questions.append(api_question)

        total_time = time.time() - generation_start

        return JSONResponse(
            status_code=200,
            content={
                "message": "í€´ì¦ˆ ìƒì„± ì„±ê³µ",
                "quiz_id": response.quiz_id,
                "document_id": response.document_id,
                "questions": [q.__dict__ for q in api_questions],
                "total_questions": response.total_questions,
                "difficulty": response.difficulty.value,
                "generation_time": response.generation_time,
                "api_processing_time": round(total_time, 3),
                "created_at": response.created_at,

                # ğŸ“Š ìƒì„± í†µê³„ ë° í’ˆì§ˆ ì •ë³´
                "generation_info": {
                    "llm_model_used": response.metadata.get("llm_model"),
                    "extracted_topics": response.metadata.get("extracted_topics", []),
                    "contexts_used": response.metadata.get("contexts_used", 0),
                    "avg_context_similarity": round(response.metadata.get("avg_context_similarity", 0), 3),
                    "question_types_generated": response.metadata.get("generation_stats", {}).get("question_types_used", [])
                },

                # ğŸ” í’ˆì§ˆ ê²€ì¦ ê²°ê³¼
                "quality_assessment": response.metadata.get("validation_result", {}),

                # ğŸ’¡ ì‚¬ìš© íŒ
                "usage_tips": {
                    "quiz_id": "ì´ quiz_idë¡œ í€´ì¦ˆ ê²°ê³¼ë¥¼ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                    "question_navigation": "questions ë°°ì—´ì˜ ê° ë¬¸ì œëŠ” topicê³¼ source_contextë¥¼ í¬í•¨í•©ë‹ˆë‹¤",
                    "quality_improvement": "ë” ë‚˜ì€ í’ˆì§ˆì„ ìœ„í•´ specific topicsë¥¼ ì§€ì •í•˜ê±°ë‚˜ difficultyë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”"
                }
            }
        )

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        error_time = time.time() - generation_start
        logger.error(f"í€´ì¦ˆ ìƒì„± API ì˜¤ë¥˜: {str(e)} ({error_time:.2f}ì´ˆ)")
        raise HTTPException(status_code=500, detail=f"í€´ì¦ˆ ìƒì„± ì˜¤ë¥˜: {str(e)}")


@router.get("/topics/{document_id}")
async def extract_document_topics(
    document_id: str = Path(..., description="ë¬¸ì„œ ID"),
    max_topics: int = Query(10, ge=1, le=20, description="ìµœëŒ€ í† í”½ ìˆ˜")
) -> JSONResponse:
    """ğŸ“ ë¬¸ì„œì—ì„œ ì£¼ìš” í† í”½ ì¶”ì¶œ

    í€´ì¦ˆ ìƒì„± ì „ì— ë¬¸ì„œì˜ ì£¼ìš” í† í”½ë“¤ì„ ë¯¸ë¦¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    ì¶”ì¶œëœ í† í”½ì„ /quiz/generateì˜ topics íŒŒë¼ë¯¸í„°ì— í™œìš©í•˜ì„¸ìš”.
    """

    logger.info(f"í† í”½ ì¶”ì¶œ ìš”ì²­: {document_id}")

    try:
        extraction_start = time.time()

        # í† í”½ ì¶”ì¶œ
        topics = quiz_service.extract_topics(document_id)

        if not topics:
            raise HTTPException(
                status_code=404,
                detail=f"ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ í† í”½ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {document_id}"
            )

        extraction_time = time.time() - extraction_start

        # í† í”½ ìˆ˜ ì œí•œ
        limited_topics = topics[:max_topics]

        return JSONResponse(
            status_code=200,
            content={
                "message": "í† í”½ ì¶”ì¶œ ì„±ê³µ",
                "document_id": document_id,
                "total_topics_found": len(topics),
                "returned_topics": len(limited_topics),
                "extraction_time": round(extraction_time, 3),
                "topics": limited_topics,
                "llm_model_used": quiz_service.llm_service.model_name,
                "recommendations": {
                    "quiz_generation": "ì´ í† í”½ë“¤ì„ /quiz/generate APIì˜ topics íŒŒë¼ë¯¸í„°ì— ì‚¬ìš©í•˜ì„¸ìš”",
                    "topic_selection": "ê´€ì‹¬ ìˆëŠ” í† í”½ 2-5ê°œë¥¼ ì„ íƒí•˜ë©´ ë” ì§‘ì¤‘ëœ í€´ì¦ˆë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                    "difficulty_matching": "í† í”½ì˜ ë³µì¡ë„ì— ë”°ë¼ difficulty íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì„¸ìš”"
                }
            }
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"í† í”½ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í† í”½ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")


@router.post("/switch-llm")
async def switch_llm_model(
    provider: str = Body(..., description="LLM ì œê³µì—…ì²´"),
    model_name: str = Body(..., description="ëª¨ë¸ ì´ë¦„"),
    api_key: Optional[str] = Body(None, description="API í‚¤ (ì„ íƒì‚¬í•­)")
) -> JSONResponse:
    """ğŸ”„ LLM ëª¨ë¸ êµì²´

    ë‹¤ë¥¸ LLM ëª¨ë¸ë¡œ ì „í™˜í•˜ì—¬ í€´ì¦ˆ ìƒì„± ìŠ¤íƒ€ì¼ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    **ì§€ì› ëª¨ë¸:**
    - OpenAI: gpt-4o-mini, gpt-4, gpt-3.5-turbo
    - ì¶”í›„: êµ­ë‚´ í•œêµ­ì–´ ëª¨ë¸ë“¤

    **ì˜ˆì‹œ ìš”ì²­:**
    ```json
    {
        "provider": "openai",
        "model_name": "gpt-4",
        "api_key": "sk-..."
    }
    ```
    """

    logger.info(f"LLM ëª¨ë¸ êµì²´ ìš”ì²­: {provider}/{model_name}")

    try:
        global quiz_service

        # í˜„ì¬ ëª¨ë¸ ì •ë³´ ì €ì¥
        previous_model = quiz_service.llm_service.model_name
        previous_provider = quiz_service.llm_service.provider.value

        # ì œê³µì—…ì²´ ê²€ì¦
        if provider not in LLMFactory.get_available_providers():
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì œê³µì—…ì²´: {provider}")

        # ìƒˆ LLM ì„œë¹„ìŠ¤ ìƒì„±
        config = LLMConfig(
            provider=LLMProvider(provider),
            model_name=model_name,
            api_key=api_key
        )

        new_llm_service = LLMFactory.create_llm(config)

        # í€´ì¦ˆ ì„œë¹„ìŠ¤ì˜ LLM êµì²´
        quiz_service.switch_llm_model(new_llm_service)

        return JSONResponse(
            status_code=200,
            content={
                "message": "LLM ëª¨ë¸ êµì²´ ì„±ê³µ",
                "previous_model": {
                    "provider": previous_provider,
                    "model_name": previous_model
                },
                "current_model": {
                    "provider": provider,
                    "model_name": model_name
                },
                "switch_timestamp": time.time(),
                "note": "ì´ì œ ìƒˆë¡œìš´ ëª¨ë¸ë¡œ í€´ì¦ˆê°€ ìƒì„±ë©ë‹ˆë‹¤"
            }
        )

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"LLM ëª¨ë¸ êµì²´ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"LLM ëª¨ë¸ êµì²´ ì‹¤íŒ¨: {str(e)}")


@router.get("/models")
async def get_available_models() -> JSONResponse:
    """ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ LLM ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""

    try:
        return JSONResponse(
            status_code=200,
            content={
                "message": "ì‚¬ìš© ê°€ëŠ¥í•œ LLM ëª¨ë¸ ëª©ë¡",
                "current_model": {
                    "provider": quiz_service.llm_service.provider.value,
                    "model_name": quiz_service.llm_service.model_name
                },
                "available_providers": LLMFactory.get_available_providers(),
                "provider_details": {
                    "openai": {
                        "models": ["gpt-4o-mini", "gpt-4", "gpt-3.5-turbo"],
                        "status": "available",
                        "note": "API í‚¤ í•„ìš”"
                    },
                    "anthropic": {
                        "models": ["claude-3-sonnet", "claude-3-haiku"],
                        "status": "coming_soon",
                        "note": "ì¤€ë¹„ ì¤‘"
                    },
                    "korean_local": {
                        "models": ["kullm-polyglot-12.8b-v2", "ko-alpaca"],
                        "status": "planned",
                        "note": "í•œêµ­ì–´ ìµœì í™” ëª¨ë¸ (ê³„íš ì¤‘)"
                    }
                },
                "recommendations": {
                    "korean_documents": "í•œêµ­ì–´ ë¬¸ì„œì—ëŠ” í•œêµ­ì–´ ìµœì í™” ëª¨ë¸ì„ ê¶Œì¥í•©ë‹ˆë‹¤ (ì¤€ë¹„ ì¤‘)",
                    "technical_content": "ê¸°ìˆ  ë¬¸ì„œì—ëŠ” gpt-4ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤",
                    "general_usage": "ì¼ë°˜ì ì¸ ì‚¬ìš©ì—ëŠ” gpt-4o-miniê°€ ì í•©í•©ë‹ˆë‹¤"
                }
            }
        )

    except Exception as e:
        logger.error(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")


@router.get("/examples")
async def get_usage_examples() -> JSONResponse:
    """ğŸ’¡ í€´ì¦ˆ ìƒì„± API ì‚¬ìš© ì˜ˆì‹œ"""

    return JSONResponse(
        status_code=200,
        content={
            "message": "í€´ì¦ˆ ìƒì„± API ì‚¬ìš© ì˜ˆì‹œ",
            "examples": {
                "basic_quiz": {
                    "description": "ê¸°ë³¸ í€´ì¦ˆ ìƒì„±",
                    "request": {
                        "document_id": "doc_12345",
                        "num_questions": 5,
                        "difficulty": "medium"
                    },
                    "note": "ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ í† í”½ì„ ì¶”ì¶œí•˜ê³  ë¬¸ì œ ìœ í˜•ì„ ê²°ì •í•©ë‹ˆë‹¤"
                },
                "specific_topics": {
                    "description": "íŠ¹ì • í† í”½ ì§‘ì¤‘ í€´ì¦ˆ",
                    "request": {
                        "document_id": "doc_12345",
                        "num_questions": 10,
                        "difficulty": "hard",
                        "topics": ["ì•Œê³ ë¦¬ì¦˜", "ìë£Œêµ¬ì¡°", "ë³µì¡ë„"]
                    },
                    "note": "ì§€ì •ëœ í† í”½ì— ì§‘ì¤‘ëœ ë¬¸ì œê°€ ìƒì„±ë©ë‹ˆë‹¤"
                },
                "custom_question_types": {
                    "description": "ë¬¸ì œ ìœ í˜• ì§€ì •",
                    "request": {
                        "document_id": "doc_12345",
                        "num_questions": 8,
                        "difficulty": "easy",
                        "question_types": ["multiple_choice", "true_false"]
                    },
                    "note": "ê°ê´€ì‹ê³¼ ì°¸/ê±°ì§“ ë¬¸ì œë§Œ ìƒì„±ë©ë‹ˆë‹¤"
                },
                "comprehensive_quiz": {
                    "description": "ì¢…í•© í€´ì¦ˆ",
                    "request": {
                        "document_id": "doc_12345",
                        "num_questions": 15,
                        "difficulty": "medium",
                        "topics": ["í•µì‹¬ê°œë…", "ì‘ìš©"],
                        "question_types": ["multiple_choice", "short_answer", "fill_blank"],
                        "language": "ko"
                    },
                    "note": "ë‹¤ì–‘í•œ ë¬¸ì œ ìœ í˜•ê³¼ í† í”½ì„ í¬í•¨í•œ ì¢…í•© í€´ì¦ˆ"
                }
            },
            "workflow": {
                "step1": "POST /pdf/upload - PDF ë¬¸ì„œ ì—…ë¡œë“œí•˜ì—¬ document_id íšë“",
                "step2": "GET /quiz/topics/{document_id} - ë¬¸ì„œ í† í”½ í™•ì¸ (ì„ íƒì‚¬í•­)",
                "step3": "POST /quiz/generate - í€´ì¦ˆ ìƒì„±",
                "step4": "ìƒì„±ëœ í€´ì¦ˆë¥¼ í™œìš©í•˜ì—¬ í•™ìŠµ ì§„í–‰"
            },
            "tips": {
                "quality": "ë” ë‚˜ì€ í’ˆì§ˆì„ ìœ„í•´ êµ¬ì²´ì ì¸ í† í”½ì„ ì§€ì •í•˜ì„¸ìš”",
                "performance": "ëŒ€ìš©ëŸ‰ ë¬¸ì„œì˜ ê²½ìš° í† í”½ì„ ë¯¸ë¦¬ ì¶”ì¶œí•˜ì—¬ í™œìš©í•˜ì„¸ìš”",
                "customization": "í•™ìŠµ ëª©í‘œì— ë§ê²Œ ë‚œì´ë„ì™€ ë¬¸ì œ ìœ í˜•ì„ ì¡°ì •í•˜ì„¸ìš”"
            }
        }
    )


# ì—ëŸ¬ í•¸ë“¤ëŸ¬ ì œê±° - ëŒ€ì‹  ì¼ë°˜ í•¨ìˆ˜ë¡œ ë³€ê²½
def create_error_response(exc: HTTPException) -> JSONResponse:
    """í€´ì¦ˆ API ì—ëŸ¬ ì‘ë‹µ ìƒì„± í•¨ìˆ˜"""
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": "í€´ì¦ˆ ìƒì„± ì˜¤ë¥˜",
            "detail": exc.detail,
            "suggestions": {
                "document_not_found": "document_idê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ê³ , PDFê°€ ë¨¼ì € ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”",
                "generation_failed": "ë‹¤ë¥¸ ë‚œì´ë„ë‚˜ ë” ì ì€ ë¬¸ì œ ìˆ˜ë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”",
                "invalid_parameters": "API ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì—¬ íŒŒë¼ë¯¸í„° í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”"
            },
            "helpful_endpoints": [
                "GET /quiz/health - ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸",
                "GET /quiz/examples - ì‚¬ìš© ì˜ˆì‹œ í™•ì¸",
                "GET /pdf/documents - ì—…ë¡œë“œëœ ë¬¸ì„œ ëª©ë¡ í™•ì¸"
            ]
        }
    )