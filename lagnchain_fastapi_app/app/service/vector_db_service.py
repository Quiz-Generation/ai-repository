"""
ğŸ—„ï¸ Vector Database Service
"""
import logging
import hashlib
import uuid
from typing import List, Dict, Any, Optional, Tuple
from sentence_transformers import SentenceTransformer

from ..core.vector_db.factory import VectorDBFactory
from ..core.vector_db.base import VectorDatabase, VectorDocument, SearchResult
from ..helper.text_helper import TextHelper

logger = logging.getLogger(__name__)


class VectorDBService:
    """ë²¡í„° DB ì„œë¹„ìŠ¤ - ì„ë² ë”© ìƒì„± ë° ì €ì¥ ê´€ë¦¬"""

    def __init__(self):
        self.embedding_model = None
        self.model_name = "all-MiniLM-L6-v2"  # ê²½ëŸ‰í™”ëœ ë‹¤êµ­ì–´ ì§€ì› ëª¨ë¸
        self.vector_db = None
        self.current_db_type = None
        self.fallback_order = ["milvus", "faiss"]

    async def initialize_embedding_model(self) -> None:
        """ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            logger.info("STEP_VECTOR ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹œì‘")
            self.embedding_model = SentenceTransformer(self.model_name)
            logger.info(f"SUCCESS ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.model_name}")
        except Exception as e:
            logger.error(f"ERROR ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    async def initialize_vector_db(self, preferred_db: Optional[str] = None) -> str:
        """ë²¡í„° DB ì´ˆê¸°í™” (ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ í´ë°±)"""
        db_types_to_try = [preferred_db] if preferred_db else self.fallback_order

        for db_type in db_types_to_try:
            if db_type is None:
                continue

            try:
                logger.info(f"STEP_VECTOR {db_type.upper()} ì´ˆê¸°í™” ì‹œë„")

                # ë²¡í„° DB ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì˜¬ë°”ë¥¸ ê²½ë¡œ ì‚¬ìš©)
                db_path = f"data/vector_storage/{db_type}"
                temp_db = VectorDBFactory.create(db_type, db_path)

                # í—¬ìŠ¤ì²´í¬ë¡œ ë¨¼ì € í™•ì¸
                health_status = await temp_db.health_check()
                if health_status.get("status") != "healthy":
                    logger.warning(f"WARNING {db_type.upper()} í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {health_status.get('error', 'Unknown error')}")
                    continue

                # ì´ˆê¸°í™”
                await temp_db.initialize()

                self.vector_db = temp_db
                self.current_db_type = db_type
                logger.info(f"SUCCESS {db_type.upper()} ì´ˆê¸°í™” ë° í™œì„±í™” ì™„ë£Œ")
                return db_type

            except Exception as e:
                logger.warning(f"WARNING {db_type.upper()} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                continue

        # ëª¨ë“  DB ì‹¤íŒ¨ ì‹œ ë§ˆì§€ë§‰ìœ¼ë¡œ FAISS ê°•ì œ ì‹œë„
        if not self.current_db_type:
            try:
                logger.info("STEP_VECTOR ë§ˆì§€ë§‰ ì‹œë„: FAISS ê°•ì œ ì´ˆê¸°í™”")
                db_path = f"data/vector_storage/faiss"
                self.vector_db = VectorDBFactory.create("faiss", db_path)
                await self.vector_db.initialize()
                self.current_db_type = "faiss"
                logger.info("SUCCESS FAISS ê°•ì œ ì´ˆê¸°í™” ì™„ë£Œ")
                return "faiss"
            except Exception as e:
                logger.error(f"ERROR FAISS ê°•ì œ ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {e}")

        raise RuntimeError("ëª¨ë“  ë²¡í„° DB ì´ˆê¸°í™” ì‹¤íŒ¨")

    async def store_pdf_content(
        self,
        pdf_content: str,
        metadata: Dict[str, Any],
        chunk_size: int = 1000,
        chunk_overlap: int = 200
    ) -> Dict[str, Any]:
        """PDF ë‚´ìš©ì„ ë²¡í„° DBì— ì €ì¥"""
        try:
            # ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš° ì´ˆê¸°í™”
            if not self.embedding_model:
                await self.initialize_embedding_model()

            # ë²¡í„° DBê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš° ì´ˆê¸°í™”
            if not self.vector_db:
                await self.initialize_vector_db()

            logger.info("STEP_VECTOR PDF ë‚´ìš© ì²­í‚¹ ì‹œì‘")

            # í…ìŠ¤íŠ¸ ì²­í‚¹
            chunks = TextHelper.create_text_chunks(
                pdf_content,
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap
            )

            logger.info(f"STEP_VECTOR {len(chunks)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ")

            # ì„ë² ë”© ìƒì„±
            logger.info("STEP_VECTOR ì„ë² ë”© ìƒì„± ì‹œì‘")
            embeddings = self.embedding_model.encode(chunks, show_progress_bar=True)

            # VectorDocument ê°ì²´ë“¤ ìƒì„±
            vector_documents = []
            for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
                doc_id = self._generate_document_id(chunk, metadata)

                # ì²­í¬ë³„ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                chunk_metadata = metadata.copy()
                chunk_metadata.update({
                    "chunk_index": i,
                    "total_chunks": len(chunks),
                    "chunk_size": len(chunk),
                    "embedding_model": self.model_name,
                    "vector_db_type": self.current_db_type
                })

                vector_doc = VectorDocument(
                    id=doc_id,
                    content=chunk,
                    embedding=embedding.tolist(),
                    metadata=chunk_metadata
                )
                vector_documents.append(vector_doc)

            # ë²¡í„° DBì— ì €ì¥
            logger.info(f"STEP_VECTOR {self.current_db_type.upper()}ì— ì €ì¥ ì‹œì‘")
            stored_ids = await self.vector_db.add_documents(vector_documents)

            result = {
                "success": True,
                "vector_db_type": self.current_db_type,
                "stored_document_count": len(stored_ids),
                "chunk_count": len(chunks),
                "embedding_dimension": len(embeddings[0]),
                "model_name": self.model_name,
                "stored_ids": stored_ids[:5]  # ì²˜ìŒ 5ê°œ IDë§Œ ë°˜í™˜
            }

            logger.info(f"SUCCESS PDF ë²¡í„°í™” ì €ì¥ ì™„ë£Œ: {len(stored_ids)}ê°œ ë¬¸ì„œ")
            return result

        except Exception as e:
            logger.error(f"ERROR PDF ë²¡í„°í™” ì €ì¥ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "vector_db_type": self.current_db_type
            }

    async def search_similar_content(
        self,
        query: str,
        top_k: int = 5,
        filters: Optional[Dict[str, Any]] = None
    ) -> List[SearchResult]:
        """ìœ ì‚¬í•œ ë‚´ìš© ê²€ìƒ‰"""
        try:
            # ëª¨ë¸ê³¼ DB ì´ˆê¸°í™” í™•ì¸
            if not self.embedding_model:
                await self.initialize_embedding_model()
            if not self.vector_db:
                await self.initialize_vector_db()

            logger.info(f"STEP_VECTOR ê²€ìƒ‰ ì¿¼ë¦¬: '{query[:50]}...'")

            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self.embedding_model.encode([query])[0]

            # ë²¡í„° DBì—ì„œ ê²€ìƒ‰
            results = await self.vector_db.search(
                query_embedding=query_embedding.tolist(),
                top_k=top_k,
                filters=filters
            )

            logger.info(f"SUCCESS ìœ ì‚¬ë„ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return results

        except Exception as e:
            logger.error(f"ERROR ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    async def get_vector_db_status(self) -> Dict[str, Any]:
        """ë²¡í„° DB ìƒíƒœ ì •ë³´ ì¡°íšŒ"""
        try:
            status = {
                "current_db_type": self.current_db_type,
                "embedding_model": self.model_name,
                "supported_db_types": VectorDBFactory.get_supported_types(),
                "priority_order": VectorDBFactory.get_priority_order()
            }

            # í˜„ì¬ DB í—¬ìŠ¤ì²´í¬
            if self.vector_db:
                health_info = await self.vector_db.health_check()
                status["current_db_health"] = health_info
                status["document_count"] = await self.vector_db.get_document_count()

            # ëª¨ë“  DB íƒ€ì… í—¬ìŠ¤ì²´í¬
            db_health_status = {}
            for db_type in self.fallback_order:
                try:
                    temp_db = VectorDBFactory.create(db_type, f"data/vector_storage/{db_type}")
                    health = await temp_db.health_check()
                    db_health_status[db_type] = health
                except Exception as e:
                    db_health_status[db_type] = {
                        "status": "unhealthy",
                        "error": str(e),
                        "db_type": db_type
                    }

            status["all_db_health"] = db_health_status
            return status

        except Exception as e:
            logger.error(f"ERROR ë²¡í„° DB ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "error": str(e),
                "current_db_type": self.current_db_type
            }

    async def switch_vector_db(self, new_db_type: str) -> bool:
        """ë²¡í„° DB íƒ€ì… ë³€ê²½"""
        try:
            if new_db_type not in VectorDBFactory.get_supported_types():
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” DB íƒ€ì…: {new_db_type}")

            logger.info(f"STEP_VECTOR {new_db_type.upper()}ë¡œ ì „í™˜ ì‹œë„")

            # ìƒˆ DB ì´ˆê¸°í™” (ì˜¬ë°”ë¥¸ ê²½ë¡œ ì‚¬ìš©)
            db_path = f"data/vector_storage/{new_db_type}"
            new_db = VectorDBFactory.create(new_db_type, db_path)
            await new_db.initialize()

            # ì„±ê³µ ì‹œ êµì²´
            self.vector_db = new_db
            self.current_db_type = new_db_type

            logger.info(f"SUCCESS {new_db_type.upper()}ë¡œ ì „í™˜ ì™„ë£Œ")
            return True

        except Exception as e:
            logger.error(f"ERROR ë²¡í„° DB ì „í™˜ ì‹¤íŒ¨: {e}")
            return False

    def _generate_document_id(self, content: str, metadata: Dict[str, Any]) -> str:
        """ë¬¸ì„œ ID ìƒì„± (ë‚´ìš© ê¸°ë°˜ í•´ì‹œ)"""
        # ë‚´ìš©ê³¼ ì£¼ìš” ë©”íƒ€ë°ì´í„°ë¡œ ê³ ìœ  ID ìƒì„±
        content_hash = hashlib.md5(content.encode()).hexdigest()[:8]
        filename = metadata.get("filename", "unknown")
        chunk_info = f"{metadata.get('chunk_index', 0)}"

        return f"{filename}_{content_hash}_{chunk_info}_{uuid.uuid4().hex[:8]}"

    async def delete_documents_by_filename(self, filename: str) -> Dict[str, Any]:
        """íŒŒì¼ëª…ìœ¼ë¡œ ë¬¸ì„œë“¤ ì‚­ì œ"""
        try:
            if not self.vector_db:
                await self.initialize_vector_db()

            # í•„í„°ë¡œ í•´ë‹¹ íŒŒì¼ì˜ ë¬¸ì„œë“¤ ê²€ìƒ‰
            filter_condition = {"filename": filename}
            documents = await self.vector_db.search(
                query_embedding=[0.0] * 384,  # ë”ë¯¸ ì„ë² ë”©
                top_k=1000,  # ì¶©ë¶„íˆ í° ìˆ˜
                filters=filter_condition
            )

            # ì°¾ì€ ë¬¸ì„œë“¤ ì‚­ì œ
            deleted_count = 0
            for result in documents:
                success = await self.vector_db.delete_document(result.document.id)
                if success:
                    deleted_count += 1

            logger.info(f"SUCCESS {filename} ê´€ë ¨ {deleted_count}ê°œ ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ")
            return {
                "success": True,
                "deleted_count": deleted_count,
                "filename": filename
            }

        except Exception as e:
            logger.error(f"ERROR ë¬¸ì„œ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "filename": filename
            }

    async def get_all_documents(self, limit: Optional[int] = None) -> Dict[str, Any]:
        """ë²¡í„° DBì˜ ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ"""
        try:
            # ë²¡í„° DB ì´ˆê¸°í™” í™•ì¸
            if not self.vector_db:
                await self.initialize_vector_db()

            logger.info(f"STEP_VECTOR ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ ì‹œì‘ (ì œí•œ: {limit or 'ì—†ìŒ'})")

            # ë²¡í„° DBì—ì„œ ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ
            documents = await self.vector_db.get_all_documents(limit)

            # íŒŒì¼ë³„ ë¬¸ì„œ ê·¸ë£¹í™”
            files_info = {}
            for doc in documents:
                filename = doc.metadata.get("filename", "unknown")
                if filename not in files_info:
                    files_info[filename] = {
                        "filename": filename,
                        "document_count": 0,
                        "total_chunks": 0,
                        "file_size": doc.metadata.get("file_size", 0),
                        "upload_timestamp": doc.metadata.get("upload_timestamp", "unknown"),
                        "pdf_loader": doc.metadata.get("pdf_loader", "unknown"),
                        "language": doc.metadata.get("language", "unknown"),
                        "vector_db_type": doc.metadata.get("vector_db_type", self.current_db_type),
                        "first_chunk_content": ""
                    }

                files_info[filename]["document_count"] += 1
                files_info[filename]["total_chunks"] = doc.metadata.get("total_chunks", 0)

                # ì²« ë²ˆì§¸ ì²­í¬ì˜ ë‚´ìš© ì €ì¥ (ë¯¸ë¦¬ë³´ê¸°ìš©)
                if files_info[filename]["first_chunk_content"] == "":
                    content_preview = doc.content[:200] + "..." if len(doc.content) > 200 else doc.content
                    files_info[filename]["first_chunk_content"] = content_preview

            result = {
                "success": True,
                "vector_db_type": self.current_db_type,
                "total_documents": len(documents),
                "total_files": len(files_info),
                "limit_applied": limit,
                "files": list(files_info.values()),
                "embedding_model": self.model_name
            }

            logger.info(f"SUCCESS ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ ì™„ë£Œ: {len(documents)}ê°œ ë¬¸ì„œ, {len(files_info)}ê°œ íŒŒì¼")
            return result

        except Exception as e:
            logger.error(f"ERROR ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "vector_db_type": self.current_db_type,
                "total_documents": 0,
                "total_files": 0
            }