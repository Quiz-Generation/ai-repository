"""
PDF ê¸°ë°˜ RAG í€´ì¦ˆ ìƒì„± ì„œë¹„ìŠ¤
ìµœì í™”ëœ í€´ì¦ˆ ìƒì„±ì„ ìœ„í•œ ë©”ì¸ ì„œë¹„ìŠ¤
"""
import logging
import time
import uuid
from typing import List, Dict, Any, Optional, Union
from dataclasses import asdict

from ..schemas.quiz_schema import (
    QuizRequest, QuizResponse, Question, Difficulty, QuestionType,
    RAGContext, TopicAnalysis, QuizGenerationStats
)
from ..services.llm_factory import LLMFactory, BaseLLMService, get_default_llm_service
from ..services.vector_service import PDFVectorService, get_global_vector_service

logger = logging.getLogger(__name__)


class RAGRetriever:
    """RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ í´ë˜ìŠ¤"""

    def __init__(self, vector_service: PDFVectorService, llm_service: Optional[BaseLLMService] = None):
        self.vector_service = vector_service
        self.llm_service = llm_service

    def retrieve_contexts_for_quiz(
        self,
        document_id: str,
        num_questions: int,
        topics: Optional[List[str]] = None
    ) -> List[RAGContext]:
        """í€´ì¦ˆ ìƒì„±ì„ ìœ„í•œ ìµœì  ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰"""

        logger.info(f"RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹œì‘: {document_id} ({num_questions}ë¬¸ì œ)")

        # ë¬¸ì„œ ì •ë³´ í™•ì¸
        doc_info = self.vector_service.get_document_info(document_id)
        if not doc_info:
            raise ValueError(f"ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {document_id}")

        contexts = []

        # ì£¼ì œë³„ ê²€ìƒ‰ ë˜ëŠ” ë™ì  ê²€ìƒ‰
        if topics:
            # íŠ¹ì • ì£¼ì œë“¤ì— ëŒ€í•œ ê²€ìƒ‰
            for topic in topics:
                search_results = self.vector_service.search_in_document(
                    query=topic,
                    document_id=document_id,
                    top_k=max(3, num_questions // len(topics))
                )
                contexts.extend(self._convert_to_rag_contexts(search_results, topic))
        else:
            # ğŸ§  LLM ê¸°ë°˜ ë™ì  í‚¤ì›Œë“œ ìƒì„±
            logger.info("í† í”½ì´ ì—†ìŒ â†’ LLMìœ¼ë¡œ ë¬¸ì„œ ë§ì¶¤ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„± ì¤‘...")
            dynamic_queries = self._generate_dynamic_search_queries(document_id, num_questions)

            logger.info(f"ìƒì„±ëœ ë™ì  ê²€ìƒ‰ í‚¤ì›Œë“œ: {dynamic_queries}")

            for query in dynamic_queries:
                search_results = self.vector_service.search_in_document(
                    query=query,
                    document_id=document_id,
                    top_k=2
                )
                contexts.extend(self._convert_to_rag_contexts(search_results))

        # ì¤‘ë³µ ì œê±° ë° í’ˆì§ˆ í•„í„°ë§
        contexts = self._deduplicate_contexts(contexts)
        contexts = self._filter_context_quality(contexts)

        # ìœ ì‚¬ë„ ê¸°ì¤€ ì •ë ¬
        contexts.sort(key=lambda x: x.similarity, reverse=True)

        logger.info(f"RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì™„ë£Œ: {len(contexts)}ê°œ")
        return contexts[:num_questions * 2]  # ì—¬ìœ ë¶„ í™•ë³´

    def _generate_dynamic_search_queries(self, document_id: str, num_questions: int) -> List[str]:
        """ğŸ“š LLMì„ í™œìš©í•˜ì—¬ ë¬¸ì„œì— ë§ëŠ” ë™ì  ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±"""

        if not self.llm_service:
            # LLMì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ë²”ìš© í‚¤ì›Œë“œ ì‚¬ìš© (fallback)
            logger.warning("LLM ì„œë¹„ìŠ¤ê°€ ì—†ì–´ ê¸°ë³¸ í‚¤ì›Œë“œ ì‚¬ìš©")
            return ["í•µì‹¬ ë‚´ìš©", "ì£¼ìš” ê°œë…", "ì¤‘ìš”í•œ ì •ë³´", "ê¸°ë³¸ ì›ë¦¬", "ì£¼ëœ ë‚´ìš©"]

        try:
            # ë¬¸ì„œì˜ ìƒ˜í”Œ í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (ë¬¸ì„œ ì „ì²´ ê°œìš” íŒŒì•…ìš©)
            sample_contexts = self.vector_service.search_in_document(
                query="ì£¼ìš” ë‚´ìš© í•µì‹¬ ì •ë³´",
                document_id=document_id,
                top_k=3
            )

            if not sample_contexts:
                logger.warning("ë¬¸ì„œì—ì„œ ìƒ˜í”Œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return ["ì£¼ìš” ë‚´ìš©", "í•µì‹¬ ê°œë…"]

            # ìƒ˜í”Œ í…ìŠ¤íŠ¸ ê²°í•©
            sample_text = "\n".join([ctx["text"][:500] for ctx in sample_contexts])

            # LLMìœ¼ë¡œ ë¬¸ì„œ ë§ì¶¤ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±
            prompt = f"""
ë‹¤ìŒì€ ì–´ë–¤ ë¬¸ì„œì˜ ì¼ë¶€ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ë¬¸ì„œì—ì„œ í€´ì¦ˆ ìƒì„±ì„ ìœ„í•œ ìµœì ì˜ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ {num_questions//2 + 3}ê°œ ìƒì„±í•´ì£¼ì„¸ìš”.

ë¬¸ì„œ ë‚´ìš©:
{sample_text[:2000]}

ìš”êµ¬ì‚¬í•­:
1. ì´ ë¬¸ì„œì˜ ì£¼ì œì™€ ë¶„ì•¼ì— ë§ëŠ” êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ
2. í€´ì¦ˆë¡œ ë§Œë“¤ê¸° ì¢‹ì€ í•µì‹¬ ê°œë…ë“¤
3. ë„ˆë¬´ ì¼ë°˜ì ì´ì§€ ì•Šê³ , ì´ ë¬¸ì„œì— íŠ¹í™”ëœ ìš©ì–´ë“¤
4. ë‹¨ìˆœíˆ ë‹¨ì–´ê°€ ì•„ë‹Œ ì§§ì€ êµ¬ë¬¸ë„ ê°€ëŠ¥

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "search_keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3", ...]
}}
"""

            response = self.llm_service.client.chat.completions.create(
                model=self.llm_service.model_name,
                messages=[
                    {"role": "system", "content": "ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ í€´ì¦ˆ ìƒì„±ì— ìµœì í™”ëœ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=500
            )

            result_text = response.choices[0].message.content
            if result_text is None:
                raise ValueError("LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")

            # JSON íŒŒì‹±
            import json
            start_idx = result_text.find('{')
            end_idx = result_text.rfind('}') + 1

            if start_idx == -1 or end_idx == 0:
                raise ValueError("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            json_text = result_text[start_idx:end_idx]
            result = json.loads(json_text)

            keywords = result.get("search_keywords", [])

            if not keywords:
                raise ValueError("ê²€ìƒ‰ í‚¤ì›Œë“œê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

            logger.info(f"LLMì´ ìƒì„±í•œ ë™ì  í‚¤ì›Œë“œ: {keywords}")
            return keywords[:num_questions//2 + 3]  # ì ì ˆí•œ ê°œìˆ˜ë¡œ ì œí•œ

        except Exception as e:
            logger.error(f"ë™ì  ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë²”ìš© í‚¤ì›Œë“œ ë°˜í™˜
            return ["í•µì‹¬ ë‚´ìš©", "ì£¼ìš” ê°œë…", "ì¤‘ìš”í•œ ì •ë³´", "ê¸°ë³¸ ì›ë¦¬", "ì£¼ëœ ì£¼ì œ"]

    def _convert_to_rag_contexts(
        self,
        search_results: List[Dict],
        topic: Optional[str] = None
    ) -> List[RAGContext]:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ RAGContextë¡œ ë³€í™˜"""
        contexts = []

        for result in search_results:
            context = RAGContext(
                text=result["text"],
                similarity=result["similarity"],
                source=result["metadata"].get("source", ""),
                chunk_index=result["metadata"].get("chunk_index", 0),
                topic=topic,
                metadata=result["metadata"]
            )
            contexts.append(context)

        return contexts

    def _deduplicate_contexts(self, contexts: List[RAGContext]) -> List[RAGContext]:
        """ì¤‘ë³µ ì»¨í…ìŠ¤íŠ¸ ì œê±°"""
        seen_texts = set()
        unique_contexts = []

        for context in contexts:
            # í…ìŠ¤íŠ¸ì˜ ì²« 100ìë¡œ ì¤‘ë³µ ì²´í¬
            text_signature = context.text[:100].strip()
            if text_signature not in seen_texts:
                seen_texts.add(text_signature)
                unique_contexts.append(context)

        return unique_contexts

    def _filter_context_quality(self, contexts: List[RAGContext]) -> List[RAGContext]:
        """ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ í•„í„°ë§"""
        return [
            ctx for ctx in contexts
            if len(ctx.text.strip()) >= 50 and ctx.similarity >= 0.05
        ]


class TopicExtractor:
    """ì£¼ì œ ì¶”ì¶œ í´ë˜ìŠ¤"""

    def __init__(self, llm_service: BaseLLMService, vector_service: PDFVectorService):
        self.llm_service = llm_service
        self.vector_service = vector_service

    def extract_document_topics(self, document_id: str) -> List[TopicAnalysis]:
        """ğŸ“š ë¬¸ì„œì—ì„œ ì£¼ìš” í† í”½ ì¶”ì¶œ ë° ë¶„ì„ (ê°œì„ ëœ ë²„ì „)"""

        logger.info(f"ë¬¸ì„œ í† í”½ ì¶”ì¶œ ì‹œì‘: {document_id}")

        # ë¬¸ì„œì˜ ë” ë§ì€ ìƒ˜í”Œ í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (ì „ì²´ì ì¸ ì´í•´ë¥¼ ìœ„í•´)
        sample_contexts = self.vector_service.search_in_document(
            query="ì£¼ìš” ë‚´ìš© í•µì‹¬ ê°œë… ì¤‘ìš”í•œ ì •ë³´",
            document_id=document_id,
            top_k=8  # ë” ë§ì€ ìƒ˜í”Œ ìˆ˜ì§‘
        )

        if not sample_contexts:
            logger.warning(f"ë¬¸ì„œ {document_id}ì—ì„œ ìƒ˜í”Œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return []

        # ë” í° í…ìŠ¤íŠ¸ ìƒ˜í”Œ ê²°í•© (ë¬¸ì„œ ì „ì²´ íŒŒì•…)
        combined_text = "\n".join([ctx["text"] for ctx in sample_contexts])

        # ğŸ§  ê°œì„ ëœ LLM í† í”½ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
        enhanced_prompt = f"""
ë‹¤ìŒì€ íŠ¹ì • ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ë“¤ì…ë‹ˆë‹¤. ì´ ë¬¸ì„œì˜ í•µì‹¬ ì£¼ì œë“¤ì„ ë¶„ì„í•˜ì—¬ í€´ì¦ˆ ìƒì„±ì— ì í•©í•œ í† í”½ë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ë¬¸ì„œ ë‚´ìš©:
{combined_text[:4000]}

ë¶„ì„ ìš”êµ¬ì‚¬í•­:
1. ì´ ë¬¸ì„œì˜ ì£¼ìš” ë¶„ì•¼/ë„ë©”ì¸ ì‹ë³„
2. í€´ì¦ˆë¡œ ë§Œë“¤ê¸° ì¢‹ì€ êµ¬ì²´ì ì¸ ì£¼ì œë“¤ ì¶”ì¶œ
3. ê° í† í”½ì˜ ì¤‘ìš”ë„ì™€ ë‚œì´ë„ í‰ê°€
4. ë¬¸ì„œì— ì‹¤ì œë¡œ ë‚˜íƒ€ë‚˜ëŠ” ê°œë…ë“¤ë§Œ í¬í•¨

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "document_domain": "ë¬¸ì„œì˜ ì£¼ìš” ë¶„ì•¼ (ì˜ˆ: ì»´í“¨í„°ê³¼í•™, ì˜í•™, ì—­ì‚¬, ë¬¸í•™ ë“±)",
    "main_topics": [
        {{
            "topic": "êµ¬ì²´ì ì¸ ì£¼ì œëª…",
            "importance": 1-10,
            "quiz_potential": 1-10,
            "keywords": ["ê´€ë ¨", "í‚¤ì›Œë“œ", "ëª©ë¡"],
            "description": "ì´ í† í”½ì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª…"
        }}
    ]
}}
"""

        try:
            response = self.llm_service.client.chat.completions.create(
                model=self.llm_service.model_name,
                messages=[
                    {"role": "system", "content": "ë¬¸ì„œ ë¶„ì„ ë° í† í”½ ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì„œì—ì„œ í€´ì¦ˆ ìƒì„±ì— ìµœì í™”ëœ ì£¼ì œë“¤ì„ ì •í™•íˆ ì‹ë³„í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": enhanced_prompt}
                ],
                temperature=0.2,  # ë” ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ ë‚®ì€ ì˜¨ë„
                max_tokens=1000
            )

            result_text = response.choices[0].message.content
            if result_text is None:
                raise ValueError("LLM í† í”½ ì¶”ì¶œ ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")

            # JSON íŒŒì‹±
            import json
            start_idx = result_text.find('{')
            end_idx = result_text.rfind('}') + 1

            if start_idx == -1 or end_idx == 0:
                raise ValueError("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            json_text = result_text[start_idx:end_idx]
            result = json.loads(json_text)

            # ê²°ê³¼ íŒŒì‹± ë° TopicAnalysis ê°ì²´ ìƒì„±
            topic_analyses = []
            main_topics = result.get("main_topics", [])
            document_domain = result.get("document_domain", "ì¼ë°˜")

            logger.info(f"ë¬¸ì„œ ë„ë©”ì¸ ì‹ë³„: {document_domain}")

            for topic_data in main_topics:
                # ê° í† í”½ë³„ ì‹¤ì œ ë¬¸ì„œ ê²€ìƒ‰ìœ¼ë¡œ ê²€ì¦
                topic_name = topic_data.get("topic", "")
                if not topic_name:
                    continue

                analysis = self._analyze_topic_enhanced(document_id, topic_name, topic_data)
                if analysis.confidence > 0.1:  # ìµœì†Œ ì‹ ë¢°ë„ í•„í„°
                    topic_analyses.append(analysis)

            # ì¤‘ìš”ë„ì™€ í€´ì¦ˆ ê°€ëŠ¥ì„± ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            topic_analyses.sort(key=lambda x: (x.question_potential, x.confidence), reverse=True)

            logger.info(f"í† í”½ ì¶”ì¶œ ì™„ë£Œ: {len(topic_analyses)}ê°œ (ë„ë©”ì¸: {document_domain})")
            return topic_analyses[:12]  # ìµœëŒ€ 12ê°œ í† í”½

        except Exception as e:
            logger.error(f"ê°œì„ ëœ í† í”½ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ fallback
            return self._fallback_topic_extraction(combined_text)

    def _analyze_topic_enhanced(self, document_id: str, topic: str, topic_data: Dict) -> TopicAnalysis:
        """ê°œì„ ëœ ê°œë³„ í† í”½ ë¶„ì„"""

        # í† í”½ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ë” ì •í™•í•œ ê²€ìƒ‰)
        search_results = self.vector_service.search_in_document(
            query=topic,
            document_id=document_id,
            top_k=4
        )

        if not search_results:
            return TopicAnalysis(
                topic=topic,
                confidence=0.1,
                keywords=topic_data.get("keywords", []),
                context_chunks=[],
                question_potential=1
            )

        # í‰ê·  ìœ ì‚¬ë„ë¡œ ì‹ ë¢°ë„ ê³„ì‚°
        avg_similarity = sum(r["similarity"] for r in search_results) / len(search_results)

        # LLMì—ì„œ ì œê³µí•œ ë©”íƒ€ë°ì´í„° í™œìš©
        importance = topic_data.get("importance", 5)
        quiz_potential_base = topic_data.get("quiz_potential", 5)

        # ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ì™€ LLM í‰ê°€ ì¡°í•©
        final_quiz_potential = min(10, int(
            (quiz_potential_base * 0.7) + (avg_similarity * 10 * 0.3)
        ))

        return TopicAnalysis(
            topic=topic,
            confidence=avg_similarity,
            keywords=topic_data.get("keywords", []),
            context_chunks=[r["text"][:300] for r in search_results],
            question_potential=final_quiz_potential
        )

    def _fallback_topic_extraction(self, text: str) -> List[TopicAnalysis]:
        """LLM ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í† í”½ ì¶”ì¶œ ë°©ì‹"""
        logger.info("ê¸°ë³¸ í† í”½ ì¶”ì¶œ ë°©ì‹ìœ¼ë¡œ fallback")

        # ê¸°ì¡´ ê°„ë‹¨í•œ ë°©ì‹
        topics = self.llm_service.extract_topics(text)

        topic_analyses = []
        for topic in topics:
            analysis = TopicAnalysis(
                topic=topic,
                confidence=0.5,
                keywords=[],
                context_chunks=[],
                question_potential=5
            )
            topic_analyses.append(analysis)

        return topic_analyses


class QuizValidator:
    """í€´ì¦ˆ í’ˆì§ˆ ê²€ì¦ í´ë˜ìŠ¤"""

    def __init__(self, llm_service: BaseLLMService):
        self.llm_service = llm_service

    def validate_quiz_quality(self, questions: List[Question]) -> Dict[str, Any]:
        """í€´ì¦ˆ ì „ì²´ í’ˆì§ˆ ê²€ì¦"""

        validation_result = {
            "overall_quality": "good",
            "total_questions": len(questions),
            "valid_questions": 0,
            "issues": [],
            "recommendations": []
        }

        valid_count = 0

        for i, question in enumerate(questions):
            question_dict = asdict(question)
            if self.llm_service.validate_question_quality(question_dict):
                valid_count += 1
            else:
                validation_result["issues"].append(f"ë¬¸ì œ {i+1}: í’ˆì§ˆ ê¸°ì¤€ ë¯¸ë‹¬")

        validation_result["valid_questions"] = valid_count

        # ì „ì²´ í’ˆì§ˆ í‰ê°€
        quality_ratio = valid_count / len(questions) if questions else 0

        if quality_ratio >= 0.8:
            validation_result["overall_quality"] = "excellent"
        elif quality_ratio >= 0.6:
            validation_result["overall_quality"] = "good"
        elif quality_ratio >= 0.4:
            validation_result["overall_quality"] = "fair"
            validation_result["recommendations"].append("ë¬¸ì œ í’ˆì§ˆ ê°œì„  í•„ìš”")
        else:
            validation_result["overall_quality"] = "poor"
            validation_result["recommendations"].append("ë¬¸ì œ ì¬ìƒì„± ê¶Œì¥")

        return validation_result


class QuizService:
    """PDF ê¸°ë°˜ í€´ì¦ˆ ìƒì„± ë©”ì¸ ì„œë¹„ìŠ¤"""

    def __init__(
        self,
        vector_service: Optional[PDFVectorService] = None,
        llm_service: Optional[BaseLLMService] = None
    ):
        """í€´ì¦ˆ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""

        # ë²¡í„° ì„œë¹„ìŠ¤ (PDF ì„œë¹„ìŠ¤ì™€ ë™ì¼í•œ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ê³µìœ )
        if vector_service is None:
            self.vector_service = get_global_vector_service()
        else:
            self.vector_service = vector_service

        # LLM ì„œë¹„ìŠ¤ (ê¸°ë³¸: OpenAI GPT-4o-mini)
        self.llm_service = llm_service or get_default_llm_service()

        # í•˜ìœ„ ì»´í¬ë„ŒíŠ¸ë“¤
        self.rag_retriever = RAGRetriever(self.vector_service, self.llm_service)
        self.topic_extractor = TopicExtractor(self.llm_service, self.vector_service)
        self.quiz_validator = QuizValidator(self.llm_service)

        logger.info(f"í€´ì¦ˆ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ: LLM={self.llm_service.model_name}, VectorDB={self.vector_service.db_type}")

    def generate_quiz(self, request: QuizRequest) -> QuizResponse:
        """ë©”ì¸ í€´ì¦ˆ ìƒì„± ë©”ì„œë“œ - í† í”½ì€ í•­ìƒ ìë™ ì¶”ì¶œ"""

        start_time = time.time()
        quiz_id = str(uuid.uuid4())

        logger.info(f"í€´ì¦ˆ ìƒì„± ì‹œì‘: {request.document_id} ({request.num_questions}ë¬¸ì œ)")

        try:
            # 1ë‹¨ê³„: ë¬¸ì„œ ì¡´ì¬ í™•ì¸
            doc_info = self.vector_service.get_document_info(request.document_id)
            if not doc_info:
                raise ValueError(f"ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {request.document_id}")

            logger.info(f"ë¬¸ì„œ í™•ì¸ ì™„ë£Œ: {doc_info['source_filename']} ({doc_info['chunk_count']}ê°œ ì²­í¬)")

            # 2ë‹¨ê³„: í† í”½ ìë™ ì¶”ì¶œ (ì™„ì „ ìë™í™”)
            logger.info("STEP1: ë¬¸ì„œ í† í”½ ìë™ ì¶”ì¶œ ì¤‘...")
            topic_analyses = self.topic_extractor.extract_document_topics(request.document_id)
            extracted_topics = [ta.topic for ta in topic_analyses[:7]]  # ìƒìœ„ 7ê°œ í† í”½

            logger.info(f"ìë™ ì¶”ì¶œëœ í† í”½: {extracted_topics}")

            # 3ë‹¨ê³„: RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
            logger.info("STEP2: RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¤‘...")
            contexts = self.rag_retriever.retrieve_contexts_for_quiz(
                document_id=request.document_id,
                num_questions=request.num_questions,
                topics=extracted_topics
            )

            if not contexts:
                raise ValueError("í€´ì¦ˆ ìƒì„±ì„ ìœ„í•œ ì ì ˆí•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            # 4ë‹¨ê³„: ì»¨í…ìŠ¤íŠ¸ ê²°í•©
            combined_context = self._combine_contexts(contexts)
            logger.info(f"ê²°í•©ëœ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(combined_context)}ì")

            # 5ë‹¨ê³„: ë¬¸ì œ ìœ í˜• ê²°ì •
            question_types = self._determine_question_types(request)

            # 6ë‹¨ê³„: LLMìœ¼ë¡œ í€´ì¦ˆ ìƒì„±
            logger.info("STEP3: LLM í€´ì¦ˆ ìƒì„± ì¤‘...")
            llm_result = self.llm_service.generate_quiz(
                context=combined_context,
                num_questions=request.num_questions,
                difficulty=request.difficulty.value,
                question_types=[qt.value for qt in question_types],
                topics=extracted_topics
            )

            if not llm_result.get("success", False):
                raise ValueError(f"LLM í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: {llm_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")

            # 7ë‹¨ê³„: ì‘ë‹µ ë°ì´í„°ë¥¼ Question ê°ì²´ë¡œ ë³€í™˜
            logger.info("STEP4: ë¬¸ì œ ë°ì´í„° ë³€í™˜ ì¤‘...")
            questions = self._convert_to_question_objects(
                llm_result["questions"],
                contexts,
                request.difficulty  # base_difficultyë¡œ ì „ë‹¬
            )

            # 8ë‹¨ê³„: í’ˆì§ˆ ê²€ì¦
            logger.info("STEP5: ë¬¸ì œ í’ˆì§ˆ ê²€ì¦ ì¤‘...")
            validation_result = self.quiz_validator.validate_quiz_quality(questions)

            # 9ë‹¨ê³„: ì‘ë‹µ ìƒì„±
            generation_time = time.time() - start_time

            response = QuizResponse(
                quiz_id=quiz_id,
                document_id=request.document_id,
                questions=questions,
                total_questions=len(questions),
                difficulty=request.difficulty,
                generation_time=generation_time,
                success=True,
                metadata={
                    "extracted_topics": extracted_topics,
                    "user_hint_topics": [],
                    "contexts_used": len(contexts),
                    "avg_context_similarity": sum(c.similarity for c in contexts) / len(contexts),
                    "validation_result": validation_result,
                    "llm_model": self.llm_service.model_name,
                    "document_info": doc_info,
                    "generation_stats": {
                        "context_retrieval_count": len(contexts),
                        "topic_extraction_count": len(extracted_topics),
                        "question_types_used": [qt.value for qt in question_types]
                    }
                }
            )

            logger.info(f"í€´ì¦ˆ ìƒì„± ì™„ë£Œ: {len(questions)}ë¬¸ì œ ({generation_time:.2f}ì´ˆ)")
            return response

        except Exception as e:
            error_time = time.time() - start_time
            logger.error(f"í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: {str(e)} ({error_time:.2f}ì´ˆ)")

            return QuizResponse(
                quiz_id=quiz_id,
                document_id=request.document_id,
                questions=[],
                total_questions=0,
                difficulty=request.difficulty,
                generation_time=error_time,
                success=False,
                error=str(e)
            )

    def extract_topics(self, document_id: str) -> List[str]:
        """ë¬¸ì„œ í† í”½ ì¶”ì¶œ (ì™¸ë¶€ APIìš©)"""
        try:
            topic_analyses = self.topic_extractor.extract_document_topics(document_id)
            return [ta.topic for ta in topic_analyses]
        except Exception as e:
            logger.error(f"í† í”½ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def validate_question_quality(self, question: Question) -> bool:
        """ê°œë³„ ë¬¸ì œ í’ˆì§ˆ ê²€ì¦ (ì™¸ë¶€ APIìš©)"""
        question_dict = asdict(question)
        return self.llm_service.validate_question_quality(question_dict)

    def retrieve_topic_contexts(self, document_id: str, topic: str) -> List[Dict]:
        """íŠ¹ì • í† í”½ì˜ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ì™¸ë¶€ APIìš©)"""
        try:
            contexts = self.rag_retriever.retrieve_contexts_for_quiz(
                document_id=document_id,
                num_questions=5,  # ê¸°ë³¸ê°’
                topics=[topic]
            )
            return [asdict(ctx) for ctx in contexts]
        except Exception as e:
            logger.error(f"í† í”½ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def switch_llm_model(self, llm_service: BaseLLMService):
        """LLM ëª¨ë¸ êµì²´"""
        old_model = self.llm_service.model_name
        self.llm_service = llm_service

        # í•˜ìœ„ ì»´í¬ë„ŒíŠ¸ë“¤ë„ ì—…ë°ì´íŠ¸
        self.topic_extractor.llm_service = llm_service
        self.quiz_validator.llm_service = llm_service

        logger.info(f"LLM ëª¨ë¸ êµì²´: {old_model} â†’ {llm_service.model_name}")

    def _combine_contexts(self, contexts: List[RAGContext]) -> str:
        """ì—¬ëŸ¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê²°í•©"""
        combined = []

        for i, context in enumerate(contexts):
            section = f"[ì„¹ì…˜ {i+1}]\n{context.text}\n"
            combined.append(section)

        return "\n".join(combined)

    def _determine_question_types(self, request: QuizRequest) -> List[QuestionType]:
        """ë¬¸ì œ ìœ í˜• ê²°ì •"""
        if request.question_types:
            return request.question_types

        # ê¸°ë³¸ ë¬¸ì œ ìœ í˜• ì¡°í•© (ë‚œì´ë„ë³„)
        if request.difficulty == Difficulty.EASY:
            return [QuestionType.MULTIPLE_CHOICE, QuestionType.TRUE_FALSE]
        elif request.difficulty == Difficulty.MEDIUM:
            return [QuestionType.MULTIPLE_CHOICE, QuestionType.SHORT_ANSWER, QuestionType.FILL_BLANK]
        else:  # HARD
            return [QuestionType.SHORT_ANSWER, QuestionType.MULTIPLE_CHOICE, QuestionType.FILL_BLANK]

    def _convert_to_question_objects(
        self,
        llm_questions: List[Dict],
        contexts: List[RAGContext],
        base_difficulty: Difficulty
    ) -> List[Question]:
        """LLM ì‘ë‹µì„ Question ê°ì²´ë¡œ ë³€í™˜ (ë¬¸ì œë³„ ë‚œì´ë„ ë‹¤ì–‘í™”)"""
        questions = []

        for i, q_data in enumerate(llm_questions):
            try:
                # ë¬¸ì œ ìœ í˜• ë³€í™˜
                question_type = QuestionType(q_data.get("question_type", "multiple_choice"))

                # ğŸ“Š ë¬¸ì œë³„ ë‚œì´ë„ ìë™ í• ë‹¹ (ë‹¤ì–‘í™”)
                if len(llm_questions) >= 3:
                    # 3ë¬¸ì œ ì´ìƒì´ë©´ ë‚œì´ë„ ë¶„ì‚°
                    if i % 3 == 0:
                        difficulty = Difficulty.EASY
                    elif i % 3 == 1:
                        difficulty = base_difficulty  # ê¸°ë³¸ ë‚œì´ë„ ìœ ì§€
                    else:
                        difficulty = Difficulty.HARD
                else:
                    # 3ë¬¸ì œ ë¯¸ë§Œì´ë©´ ê¸°ë³¸ ë‚œì´ë„ ì‚¬ìš©
                    difficulty = base_difficulty

                # ì†ŒìŠ¤ ì»¨í…ìŠ¤íŠ¸ ì°¾ê¸°
                source_context = ""
                if i < len(contexts):
                    source_context = contexts[i].text[:200] + "..."

                question = Question(
                    question=q_data.get("question", ""),
                    question_type=question_type,
                    correct_answer=q_data.get("correct_answer", ""),
                    options=q_data.get("options"),
                    explanation=q_data.get("explanation", ""),
                    difficulty=difficulty,  # ê°œë³„ ë¬¸ì œ ë‚œì´ë„
                    source_context=source_context,
                    topic=q_data.get("topic", "ì¼ë°˜"),
                    metadata={
                        "llm_generated": True,
                        "context_similarity": contexts[i].similarity if i < len(contexts) else 0,
                        "generation_order": i + 1,
                        "assigned_difficulty": difficulty.value  # í• ë‹¹ëœ ë‚œì´ë„ ì¶”ê°€
                    }
                )

                questions.append(question)

            except Exception as e:
                logger.warning(f"ë¬¸ì œ {i+1} ë³€í™˜ ì‹¤íŒ¨: {e}")
                continue

        return questions


# ì „ì—­ í€´ì¦ˆ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)
_default_quiz_service: Optional[QuizService] = None


def get_default_quiz_service() -> QuizService:
    """ê¸°ë³¸ í€´ì¦ˆ ì„œë¹„ìŠ¤ ë°˜í™˜"""
    global _default_quiz_service

    if _default_quiz_service is None:
        _default_quiz_service = QuizService()
        logger.info("ê¸°ë³¸ í€´ì¦ˆ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")

    return _default_quiz_service


if __name__ == "__main__":
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
    print("=== í€´ì¦ˆ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ===")

    try:
        quiz_service = QuizService()
        print(f"í€´ì¦ˆ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì„±ê³µ: LLM={quiz_service.llm_service.model_name}")
    except Exception as e:
        print(f"í€´ì¦ˆ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")