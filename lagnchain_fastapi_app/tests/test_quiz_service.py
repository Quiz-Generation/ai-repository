#!/usr/bin/env python3
"""
ğŸ§ª ì¤‘ë³µ ì™„ì „ ì œê±° + 2:6:2 ë¹„ìœ¨ í€´ì¦ˆ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
- ê°•í™”ëœ ì¤‘ë³µ ì œê±° ì‹œìŠ¤í…œ
- OX:ê°ê´€ì‹:ì£¼ê´€ì‹ = 2:6:2 ë¹„ìœ¨
- ì‚¬ìš©ì ì„ íƒ ê°€ëŠ¥ (ì „ë¶€ OX/ê°ê´€ì‹/ì£¼ê´€ì‹)
"""
import pytest
import os
from unittest.mock import Mock, patch, AsyncMock
from typing import List, Dict, Any, Optional

# ì‹¤ì œ ì„œë¹„ìŠ¤ import
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.schemas.quiz_schema import (
    QuizRequest, QuizResponse, Question, Difficulty, QuestionType, RAGContext
)
from app.services.advanced_quiz_service import (
    AdvancedQuizService, MultiStageRAGRetriever,
    QuestionTypeSpecialist, AdvancedQuizValidator
)
from app.services.vector_service import PDFVectorService
from app.services.llm_factory import BaseLLMService


class TestAdvancedQuizService:
    """ğŸ“ ì¤‘ë³µ ì œê±° + 2:6:2 ë¹„ìœ¨ ê³ ê¸‰ í€´ì¦ˆ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def mock_vector_service(self):
        """ë²¡í„° ì„œë¹„ìŠ¤ ëª¨í‚¹"""
        mock = Mock(spec=PDFVectorService)
        mock.get_document_info.return_value = {
            "document_id": "test-aws-doc",
            "filename": "AWS_Solutions_Architect.pdf",
            "chunk_count": 100,
            "total_chars": 50000
        }

        # ë‹¤ì–‘í•œ AWS ì»¨í…ìŠ¤íŠ¸ ëª¨í‚¹
        mock.search_in_document.return_value = [
            {
                "text": "Amazon EC2 Auto Scaling helps maintain application availability and allows you to automatically add or remove EC2 instances according to conditions you define.",
                "similarity": 0.95,
                "metadata": {"chunk_index": 1, "source": "AWS_EC2.pdf"}
            },
            {
                "text": "Amazon S3 provides industry-leading scalability, data availability, security, and performance for object storage.",
                "similarity": 0.90,
                "metadata": {"chunk_index": 2, "source": "AWS_S3.pdf"}
            },
            {
                "text": "Amazon RDS makes it easy to set up, operate, and scale a relational database in the cloud.",
                "similarity": 0.85,
                "metadata": {"chunk_index": 3, "source": "AWS_RDS.pdf"}
            }
        ]
        return mock

    @pytest.fixture
    def mock_llm_service(self):
        """LLM ì„œë¹„ìŠ¤ ëª¨í‚¹"""
        mock = Mock(spec=BaseLLMService)
        mock.model_name = "gpt-4o-mini"

        # ğŸ”¥ provider Mock ê°ì²´ë¡œ ìˆ˜ì •
        mock.provider = Mock()
        mock.provider.value = "openai"

        # ë‹¤ì–‘í•œ ë¬¸ì œ ìœ í˜• ì‘ë‹µ ëª¨í‚¹
        def create_mock_response(question_type):
            if question_type == "true_false":
                return '''
{
    "questions": [
        {
            "question": "AWS EC2ëŠ” ì„œë²„ë¦¬ìŠ¤ ì»´í“¨íŒ… ì„œë¹„ìŠ¤ì´ë‹¤.",
            "question_type": "true_false",
            "correct_answer": "False",
            "explanation": "AWS EC2ëŠ” ê°€ìƒ ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤ë¡œ, ì„œë²„ë¦¬ìŠ¤ê°€ ì•„ë‹™ë‹ˆë‹¤.",
            "difficulty": "medium",
            "topic": "AWS ì»´í“¨íŒ…"
        }
    ]
}
'''
            elif question_type == "multiple_choice":
                return '''
{
    "questions": [
        {
            "question": "AWSì—ì„œ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê³ ê°€ìš©ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ ê°€ì¥ ì ì ˆí•œ ì„œë¹„ìŠ¤ëŠ”?",
            "question_type": "multiple_choice",
            "options": ["Amazon EC2 Auto Scaling", "Amazon S3", "Amazon CloudWatch", "AWS Lambda"],
            "correct_answer": "Amazon EC2 Auto Scaling",
            "explanation": "Auto Scalingì€ ì •ì˜ëœ ì¡°ê±´ì— ë”°ë¼ ìë™ìœ¼ë¡œ EC2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ì œê±°í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°€ìš©ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.",
            "difficulty": "medium",
            "topic": "AWS ì»´í“¨íŒ…"
        }
    ]
}
'''
            else:  # short_answer
                return '''
{
    "questions": [
        {
            "question": "AWSì—ì„œ ì •ì  ì›¹ì‚¬ì´íŠ¸ í˜¸ìŠ¤íŒ…ì— ê°€ì¥ ì í•©í•œ ì„œë¹„ìŠ¤ëŠ”?",
            "question_type": "short_answer",
            "correct_answer": "Amazon S3",
            "explanation": "S3ëŠ” ì •ì  ì›¹ì‚¬ì´íŠ¸ í˜¸ìŠ¤íŒ…ì„ ìœ„í•œ ë¹„ìš© íš¨ìœ¨ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.",
            "difficulty": "medium",
            "topic": "AWS ìŠ¤í† ë¦¬ì§€"
        }
    ]
}
'''

        mock_response = Mock()
        mock_response.choices = [Mock()]
        mock_response.choices[0].message.content = create_mock_response("multiple_choice")

        # client.chat.completions.create ëª¨í‚¹
        mock.client = Mock()
        mock.client.chat.completions.create = AsyncMock(return_value=mock_response)

        return mock

    @pytest.fixture
    def quiz_service(self, mock_vector_service, mock_llm_service):
        """í€´ì¦ˆ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤"""
        return AdvancedQuizService(
            vector_service=mock_vector_service,
            llm_service=mock_llm_service
        )

    @pytest.mark.asyncio
    async def test_service_initialization(self, quiz_service):
        """âœ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        assert quiz_service is not None
        assert quiz_service.rag_retriever is not None
        assert quiz_service.question_specialist is not None
        assert quiz_service.validator is not None

    @pytest.mark.asyncio
    async def test_ê¸°ë³¸_2_6_2_ë¹„ìœ¨_ì ìš©(self, quiz_service):
        """ğŸ”¥ ê¸°ë³¸ 2:6:2 ë¹„ìœ¨ (OX:ê°ê´€ì‹:ì£¼ê´€ì‹) í…ŒìŠ¤íŠ¸"""
        # Given: 10ë¬¸ì œ ìš”ì²­ (íƒ€ì… ì§€ì • ì—†ìŒ)
        request = QuizRequest(
            document_id="test-aws-doc",
            num_questions=10,
            difficulty=Difficulty.MEDIUM
        )

        # When: ë¬¸ì œ ìœ í˜• ë¶„ë°° ê³„ì‚°
        type_distribution = quiz_service._calculate_type_distribution(request)

        # Then: 2:6:2 ë¹„ìœ¨ í™•ì¸
        tf_count = type_distribution.get(QuestionType.TRUE_FALSE, 0)
        mc_count = type_distribution.get(QuestionType.MULTIPLE_CHOICE, 0)
        sa_count = type_distribution.get(QuestionType.SHORT_ANSWER, 0)

        assert tf_count == 2  # 20% OX
        assert mc_count == 6  # 60% ê°ê´€ì‹
        assert sa_count == 2  # 20% ì£¼ê´€ì‹

        total = tf_count + mc_count + sa_count
        assert total == 10

        print(f"âœ… 2:6:2 ë¹„ìœ¨ ì ìš©: OX {tf_count}ê°œ, ê°ê´€ì‹ {mc_count}ê°œ, ì£¼ê´€ì‹ {sa_count}ê°œ")

    @pytest.mark.asyncio
    async def test_ì‚¬ìš©ì_ì„ íƒ_ì „ë¶€_ê°ê´€ì‹(self, quiz_service):
        """ğŸ”¥ ì‚¬ìš©ì ì„ íƒ: ì „ë¶€ ê°ê´€ì‹ í…ŒìŠ¤íŠ¸"""
        # Given: ê°ê´€ì‹ë§Œ ìš”ì²­
        request = QuizRequest(
            document_id="test-aws-doc",
            num_questions=5,
            difficulty=Difficulty.MEDIUM,
            question_types=[QuestionType.MULTIPLE_CHOICE]
        )

        # When: ë¬¸ì œ ìœ í˜• ë¶„ë°° ê³„ì‚°
        type_distribution = quiz_service._calculate_type_distribution(request)

        # Then: 100% ê°ê´€ì‹ í™•ì¸
        assert type_distribution == {QuestionType.MULTIPLE_CHOICE: 5}
        print(f"âœ… ì „ë¶€ ê°ê´€ì‹: {type_distribution}")

    @pytest.mark.asyncio
    async def test_ì‚¬ìš©ì_ì„ íƒ_ì „ë¶€_OX(self, quiz_service):
        """ğŸ”¥ ì‚¬ìš©ì ì„ íƒ: ì „ë¶€ OX í…ŒìŠ¤íŠ¸"""
        # Given: OXë§Œ ìš”ì²­
        request = QuizRequest(
            document_id="test-aws-doc",
            num_questions=3,
            difficulty=Difficulty.MEDIUM,
            question_types=[QuestionType.TRUE_FALSE]
        )

        # When: ë¬¸ì œ ìœ í˜• ë¶„ë°° ê³„ì‚°
        type_distribution = quiz_service._calculate_type_distribution(request)

        # Then: 100% OX í™•ì¸
        assert type_distribution == {QuestionType.TRUE_FALSE: 3}
        print(f"âœ… ì „ë¶€ OX: {type_distribution}")

    @pytest.mark.asyncio
    async def test_OX_ë¬¸ì œ_ìƒì„±_í™•ì¸(self, quiz_service):
        """ğŸ”¥ OX ë¬¸ì œ ìƒì„± í™•ì¸"""
        # Given: OX ë¬¸ì œ ìš”ì²­
        request = QuizRequest(
            document_id="test-aws-doc",
            num_questions=2,
            difficulty=Difficulty.MEDIUM,
            question_types=[QuestionType.TRUE_FALSE]
        )

        # When: í€´ì¦ˆ ìƒì„±
        response = await quiz_service.generate_guaranteed_quiz(request)

        # Then: OX ë¬¸ì œ í™•ì¸
        assert response.success is True
        for question in response.questions:
            if question.question_type == QuestionType.TRUE_FALSE:
                assert question.correct_answer in ["True", "False"]
                assert question.options is None  # OXëŠ” ì„ íƒì§€ ì—†ìŒ
                print(f"âœ… OX ë¬¸ì œ: {question.question[:50]}... ì •ë‹µ: {question.correct_answer}")

    @pytest.mark.asyncio
    async def test_ê°•í™”ëœ_ì¤‘ë³µ_ì œê±°_ì‹œìŠ¤í…œ(self, quiz_service):
        """ğŸ”¥ ê°•í™”ëœ ì¤‘ë³µ ì œê±° ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
        # Given: í€´ì¦ˆ ìš”ì²­
        request = QuizRequest(
            document_id="test-aws-doc",
            num_questions=5,
            difficulty=Difficulty.MEDIUM
        )

        # When: í€´ì¦ˆ ìƒì„±
        response = await quiz_service.generate_guaranteed_quiz(request)

        # Then: ì¤‘ë³µ ê²€ì¦ ê²°ê³¼ í™•ì¸
        validation_result = response.metadata.get("validation_result", {})
        duplicate_analysis = validation_result.get("duplicate_analysis", {})

        duplicate_pairs = duplicate_analysis.get("duplicate_pairs", [])
        similar_pairs = duplicate_analysis.get("similar_pairs", [])
        max_similarity = duplicate_analysis.get("max_similarity", 0)

        # ê°•í™”ëœ ê¸°ì¤€ ì ìš©
        assert len(duplicate_pairs) == 0  # ì¤‘ë³µ ë¬¸ì œ 0ê°œ ëª©í‘œ
        assert len(similar_pairs) <= 1   # ìœ ì‚¬ ë¬¸ì œ ìµœëŒ€ 1ê°œ
        assert max_similarity < 0.6      # ìµœëŒ€ ìœ ì‚¬ë„ 0.6 ë¯¸ë§Œ

        print(f"âœ… ì¤‘ë³µ ì œê±° ì„±ê³¼: ì¤‘ë³µ {len(duplicate_pairs)}ê°œ, ìœ ì‚¬ {len(similar_pairs)}ê°œ, ìµœëŒ€ìœ ì‚¬ë„ {max_similarity:.3f}")

    @pytest.mark.asyncio
    async def test_ë¬¸ì œ_ìœ í˜•ë³„_íŠ¹ì„±_í™•ì¸(self, quiz_service):
        """âœ… ë¬¸ì œ ìœ í˜•ë³„ íŠ¹ì„± í™•ì¸"""
        # Given: ëª¨ë“  íƒ€ì… í¬í•¨ ìš”ì²­
        request = QuizRequest(
            document_id="test-aws-doc",
            num_questions=6,  # 2:6:2ë¡œ ë‚˜ëˆ„ê¸° ì‰¬ìš´ ìˆ˜
            difficulty=Difficulty.MEDIUM,
            question_types=[QuestionType.TRUE_FALSE, QuestionType.MULTIPLE_CHOICE, QuestionType.SHORT_ANSWER]
        )

        # When: í€´ì¦ˆ ìƒì„±
        response = await quiz_service.generate_guaranteed_quiz(request)

        # Then: ë¬¸ì œ ìœ í˜•ë³„ íŠ¹ì„± í™•ì¸
        assert response.success is True

        for question in response.questions:
            if question.question_type == QuestionType.TRUE_FALSE:
                assert question.correct_answer in ["True", "False"]
                assert question.options is None
                print(f"âœ… OX ë¬¸ì œ: ì •ë‹µ {question.correct_answer}")

            elif question.question_type == QuestionType.MULTIPLE_CHOICE:
                assert question.options is not None
                assert len(question.options) >= 4
                assert question.correct_answer in question.options
                print(f"âœ… ê°ê´€ì‹: {len(question.options)}ê°œ ì„ íƒì§€")

            elif question.question_type == QuestionType.SHORT_ANSWER:
                assert question.options is None
                assert question.correct_answer.strip()  # ë¹ˆ ë‹µë³€ ì•„ë‹˜
                print(f"âœ… ì£¼ê´€ì‹: ì •ë‹µ ê¸¸ì´ {len(question.correct_answer)}ì")

    @pytest.mark.asyncio
    async def test_í’ˆì§ˆ_ì ìˆ˜_ê°œì„ _í™•ì¸(self, quiz_service):
        """ğŸ” í’ˆì§ˆ ì ìˆ˜ ê°œì„  í™•ì¸"""
        # Given: í€´ì¦ˆ ìš”ì²­
        request = QuizRequest(
            document_id="test-aws-doc",
            num_questions=5,
            difficulty=Difficulty.MEDIUM
        )

        # When: í€´ì¦ˆ ìƒì„±
        response = await quiz_service.generate_guaranteed_quiz(request)

        # Then: í’ˆì§ˆ ì ìˆ˜ í™•ì¸
        validation_result = response.metadata.get("validation_result", {})
        quality_score = validation_result.get("overall_score", 0)

        # ì¤‘ë³µ ì œê±° ì‹œìŠ¤í…œìœ¼ë¡œ í’ˆì§ˆ í–¥ìƒ ê¸°ëŒ€
        assert quality_score >= 7.0  # ë†’ì€ í’ˆì§ˆ ê¸°ì¤€

        individual_scores = validation_result.get("individual_scores", [])
        if individual_scores:
            avg_individual = sum(individual_scores) / len(individual_scores)
            assert avg_individual >= 7.0

        print(f"âœ… í’ˆì§ˆ ì ìˆ˜: ì „ì²´ {quality_score}/10, ê°œë³„ í‰ê·  {avg_individual:.1f}/10")

    @pytest.mark.asyncio
    async def test_ë©”íƒ€ë°ì´í„°_ì •ë³´_í™•ì¸(self, quiz_service):
        """ğŸ“Š ë©”íƒ€ë°ì´í„° ì •ë³´ í™•ì¸"""
        # Given: í€´ì¦ˆ ìš”ì²­
        request = QuizRequest(
            document_id="test-aws-doc",
            num_questions=5,
            difficulty=Difficulty.MEDIUM
        )

        # When: í€´ì¦ˆ ìƒì„±
        response = await quiz_service.generate_guaranteed_quiz(request)

        # Then: ë©”íƒ€ë°ì´í„° í™•ì¸
        metadata = response.metadata

        assert metadata.get("generation_method") == "duplicate_free_2_6_2_ratio"
        assert metadata.get("ratio_applied") == "2:6:2 (OX:ê°ê´€ì‹:ì£¼ê´€ì‹)"
        assert metadata.get("duplicate_prevention") == "ê°•í™”ëœ ì¤‘ë³µ ì œê±° ì ìš©"
        assert metadata.get("similarity_threshold") == 0.6

        advanced_features = metadata.get("advanced_features", [])
        assert "ğŸ”¥ ì™„ì „í•œ ì¤‘ë³µ ì œê±° ì‹œìŠ¤í…œ" in advanced_features
        assert "ğŸ”¥ 2:6:2 ë¹„ìœ¨ (OX:ê°ê´€ì‹:ì£¼ê´€ì‹)" in advanced_features

        print(f"âœ… ë©”íƒ€ë°ì´í„° í™•ì¸: {metadata['generation_method']}")

    @pytest.mark.asyncio
    async def test_ëŒ€ìš©ëŸ‰_ë¬¸ì œ_ìƒì„±_ì•ˆì •ì„±(self, quiz_service):
        """âš¡ ëŒ€ìš©ëŸ‰ ë¬¸ì œ ìƒì„± ì•ˆì •ì„± í…ŒìŠ¤íŠ¸"""
        # Given: ë§ì€ ë¬¸ì œ ìš”ì²­
        request = QuizRequest(
            document_id="test-aws-doc",
            num_questions=20,  # ëŒ€ìš©ëŸ‰
            difficulty=Difficulty.MEDIUM
        )

        # When: í€´ì¦ˆ ìƒì„±
        response = await quiz_service.generate_guaranteed_quiz(request)

        # Then: ì•ˆì •ì„± í™•ì¸
        assert response.success is True
        assert len(response.questions) == 20

        # 2:6:2 ë¹„ìœ¨ í™•ì¸ (20ë¬¸ì œ ê¸°ì¤€)
        type_counts = {}
        for q in response.questions:
            qtype = q.question_type.value
            type_counts[qtype] = type_counts.get(qtype, 0) + 1

        # ëŒ€ëµì  ë¹„ìœ¨ í™•ì¸ (ì •í™•í•˜ì§€ ì•Šì•„ë„ ë¨)
        tf_ratio = type_counts.get("true_false", 0) / 20
        mc_ratio = type_counts.get("multiple_choice", 0) / 20

        assert 0.15 <= tf_ratio <= 0.25  # OX 15-25%
        assert 0.55 <= mc_ratio <= 0.65  # ê°ê´€ì‹ 55-65%

        print(f"âœ… ëŒ€ìš©ëŸ‰ ì•ˆì •ì„±: {type_counts}")


class TestMultiStageRAGRetriever:
    """ğŸ§  ë©€í‹° ìŠ¤í…Œì´ì§€ RAG ê²€ìƒ‰ê¸° í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def mock_vector_service(self):
        mock = Mock(spec=PDFVectorService)
        mock.search_in_document.return_value = [
            {
                "text": "AWS EC2ëŠ” í´ë¼ìš°ë“œì—ì„œ í™•ì¥ ê°€ëŠ¥í•œ ì»´í“¨íŒ… ìš©ëŸ‰ì„ ì œê³µí•©ë‹ˆë‹¤.",
                "similarity": 0.95,
                "metadata": {"chunk_index": 1, "source": "AWS_EC2.pdf"}
            }
        ]
        return mock

    @pytest.fixture
    def mock_llm_service(self):
        return Mock(spec=BaseLLMService)

    @pytest.fixture
    def rag_retriever(self, mock_vector_service, mock_llm_service):
        return MultiStageRAGRetriever(mock_vector_service, mock_llm_service)

    @pytest.mark.asyncio
    async def test_ë‹¤ì–‘ì„±_ìˆëŠ”_ì»¨í…ìŠ¤íŠ¸_ê²€ìƒ‰(self, rag_retriever):
        """ğŸ¯ ë‹¤ì–‘ì„± ìˆëŠ” ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
        # Given: ë¬¸ì„œì™€ ë¬¸ì œ ìˆ˜
        document_id = "test-aws-doc"
        num_questions = 5

        # When: ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
        contexts = await rag_retriever.retrieve_diverse_contexts(
            document_id=document_id,
            num_questions=num_questions
        )

        # Then: ì ì ˆí•œ ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜ í™•ì¸
        assert isinstance(contexts, list)
        assert len(contexts) >= 0
        print(f"âœ… ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸: {len(contexts)}ê°œ")


class TestQuestionTypeSpecialist:
    """ğŸ¯ ë¬¸ì œ ìœ í˜•ë³„ ì „ë¬¸ ìƒì„±ê¸° í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def mock_llm_service(self):
        mock = Mock(spec=BaseLLMService)
        mock.model_name = "gpt-4o-mini"

        # ê°ê´€ì‹ ì‘ë‹µ ëª¨í‚¹
        mock_response = Mock()
        mock_response.choices = [Mock()]
        mock_response.choices[0].message.content = '''
{
    "questions": [
        {
            "question": "AWSì—ì„œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ì»´í“¨íŒ… ì„œë¹„ìŠ¤ëŠ”?",
            "question_type": "multiple_choice",
            "options": ["EC2", "Lambda", "ECS", "Fargate"],
            "correct_answer": "EC2",
            "explanation": "Amazon EC2ëŠ” AWSì˜ ëŒ€í‘œì ì¸ ì»´í“¨íŒ… ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.",
            "difficulty": "medium",
            "topic": "AWS ì»´í“¨íŒ…"
        }
    ]
}
'''

        mock.client = Mock()
        mock.client.chat.completions.create = AsyncMock(return_value=mock_response)

        return mock

    @pytest.fixture
    def specialist(self, mock_llm_service):
        return QuestionTypeSpecialist(mock_llm_service)

    @pytest.mark.asyncio
    async def test_ê°ê´€ì‹_ë¬¸ì œ_ìƒì„±(self, specialist):
        """ğŸ”¥ ê°ê´€ì‹ ë¬¸ì œ ì „ë¬¸ ìƒì„± í…ŒìŠ¤íŠ¸"""
        # Given: ì»¨í…ìŠ¤íŠ¸ì™€ ìš”ì²­ ì •ë³´
        contexts = [RAGContext(
            text="AWS EC2 ê´€ë ¨ ë‚´ìš©",
            similarity=0.9,
            source="test_aws.pdf",
            chunk_index=1
        )]

        # When: ê°ê´€ì‹ ë¬¸ì œ ìƒì„±
        questions = await specialist.generate_guaranteed_questions(
            contexts=contexts,
            question_type=QuestionType.MULTIPLE_CHOICE,
            count=1,
            difficulty=Difficulty.MEDIUM,
            topic="AWS ì»´í“¨íŒ…",
            options_count=4
        )

        # Then: ê°ê´€ì‹ ë¬¸ì œ ìƒì„± í™•ì¸
        assert len(questions) >= 0
        if questions:
            assert questions[0].get("question_type") == "multiple_choice"
            print(f"âœ… ê°ê´€ì‹ ë¬¸ì œ ìƒì„±: {len(questions)}ê°œ")


class TestAdvancedQuizValidator:
    """ğŸ” ê³ ê¸‰ í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""

    @pytest.fixture
    def mock_llm_service(self):
        return Mock(spec=BaseLLMService)

    @pytest.fixture
    def validator(self, mock_llm_service):
        return AdvancedQuizValidator(mock_llm_service)

    @pytest.mark.asyncio
    async def test_ê°œë³„_ë¬¸ì œ_í’ˆì§ˆ_í‰ê°€(self, validator):
        """ğŸ“Š ê°œë³„ ë¬¸ì œ í’ˆì§ˆ í‰ê°€ í…ŒìŠ¤íŠ¸"""
        # Given: í…ŒìŠ¤íŠ¸ ë¬¸ì œ
        question = Question(
            question="AWSì—ì„œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ì»´í“¨íŒ… ì„œë¹„ìŠ¤ëŠ”?",
            question_type=QuestionType.MULTIPLE_CHOICE,
            options=["EC2", "Lambda", "ECS", "Fargate"],
            correct_answer="EC2",
            explanation="Amazon EC2ëŠ” AWSì˜ ëŒ€í‘œì ì¸ ì»´í“¨íŒ… ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.",
            difficulty=Difficulty.MEDIUM
        )

        # When: í’ˆì§ˆ í‰ê°€
        score = await validator._score_single_question(question)

        # Then: ì ì ˆí•œ ì ìˆ˜ í™•ì¸
        assert 0 <= score <= 10
        assert score >= 7.0  # ì¢‹ì€ ë¬¸ì œëŠ” 7ì  ì´ìƒ
        print(f"âœ… ë¬¸ì œ í’ˆì§ˆ ì ìˆ˜: {score}/10ì ")

    @pytest.mark.asyncio
    async def test_ì¢…í•©_í’ˆì§ˆ_ê²€ì¦(self, validator):
        """ğŸ¯ ì¢…í•© í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        # Given: í…ŒìŠ¤íŠ¸ ë¬¸ì œë“¤
        questions = [
            Question(
                question="AWS EC2ë€ ë¬´ì—‡ì¸ê°€?",
                question_type=QuestionType.MULTIPLE_CHOICE,
                options=["ì»´í“¨íŒ… ì„œë¹„ìŠ¤", "ìŠ¤í† ë¦¬ì§€ ì„œë¹„ìŠ¤", "ë„¤íŠ¸ì›Œí¬ ì„œë¹„ìŠ¤", "ë°ì´í„°ë² ì´ìŠ¤ ì„œë¹„ìŠ¤"],
                correct_answer="ì»´í“¨íŒ… ì„œë¹„ìŠ¤",
                explanation="EC2ëŠ” í´ë¼ìš°ë“œ ì»´í“¨íŒ… ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.",
                difficulty=Difficulty.MEDIUM
            ),
            Question(
                question="S3ì˜ ì£¼ìš” ìš©ë„ëŠ”?",
                question_type=QuestionType.SHORT_ANSWER,
                correct_answer="ê°ì²´ ìŠ¤í† ë¦¬ì§€",
                explanation="S3ëŠ” ê°ì²´ ìŠ¤í† ë¦¬ì§€ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.",
                difficulty=Difficulty.EASY
            )
        ]

        # When: ì¢…í•© í’ˆì§ˆ ê²€ì¦
        validation_result = await validator.comprehensive_validation(questions)

        # Then: ê²€ì¦ ê²°ê³¼ í™•ì¸
        assert "overall_score" in validation_result
        assert "individual_scores" in validation_result
        assert "duplicate_analysis" in validation_result

        overall_score = validation_result["overall_score"]
        assert 0 <= overall_score <= 10
        print(f"âœ… ì¢…í•© í’ˆì§ˆ ì ìˆ˜: {overall_score}/10ì ")


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    pytest.main([__file__, "-v", "--tb=short"])
    print("\nğŸ‰ ì¤‘ë³µ ì œê±° + 2:6:2 ë¹„ìœ¨ í€´ì¦ˆ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("ğŸ”¥ 1. ê°•í™”ëœ ì¤‘ë³µ ì œê±° ì‹œìŠ¤í…œ âœ…")
    print("ğŸ”¥ 2. 2:6:2 ë¹„ìœ¨ (OX:ê°ê´€ì‹:ì£¼ê´€ì‹) âœ…")
    print("ğŸ”¥ 3. ì‚¬ìš©ì ì„ íƒ: ì „ë¶€ OX/ê°ê´€ì‹/ì£¼ê´€ì‹ âœ…")
    print("âœ… ì‹¤ì œ options í¬í•¨í•˜ëŠ” ê³ í’ˆì§ˆ ê°ê´€ì‹ ë¬¸ì œ ìƒì„±!")